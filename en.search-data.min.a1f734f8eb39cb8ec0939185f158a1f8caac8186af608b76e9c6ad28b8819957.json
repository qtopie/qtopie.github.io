[{"id":0,"href":"/notes/java/thread/","title":"JVM线程分析","section":"Notes","content":" 线程的状态 # 参考定义 java.lang.Thread.State\npublic enum State { /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * {@link Object#wait() Object.wait}. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;{@link Object#wait() Object.wait} with no timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link #join() Thread.join} with no timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#park() LockSupport.park}\u0026lt;/li\u0026gt; * \u0026lt;/ul\u0026gt; * * \u0026lt;p\u0026gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called {@code Object.wait()} * on an object is waiting for another thread to call * {@code Object.notify()} or {@code Object.notifyAll()} on * that object. A thread that has called {@code Thread.join()} * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;{@link #sleep Thread.sleep}\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link Object#wait(long) Object.wait} with timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link #join(long) Thread.join} with timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#parkNanos LockSupport.parkNanos}\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#parkUntil LockSupport.parkUntil}\u0026lt;/li\u0026gt; * \u0026lt;/ul\u0026gt; */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; } stateDiagram [*] --\u0026gt; New New --\u0026gt; Runnable : start() Runnable --\u0026gt; Blocked : acquire monitor lock Runnable --\u0026gt; Waiting : wait(), join(), park() Runnable --\u0026gt; Timed Waiting : wait(timeout), join(timeout), parkNanos(timeout) Blocked --\u0026gt; Runnable : obtain monitor lock Waiting --\u0026gt; Runnable : signaled or interrupted Timed Waiting --\u0026gt; Runnable : time elapses Runnable --\u0026gt; Terminated : run() completes waiting vs blocked # blocked: 线程试图获取一个被其他线程持有的锁（monitor），但获取失败，导致线程被阻塞 被动进入 blocked 状态的\nwaiting: 线程主动调用了方法进入等待状态，等待其他线程的通知 (wait condition)\n线程池 # 查看线程的状态 # jstack -l "},{"id":1,"href":"/notes/system-design/cache-expiration/","title":"缓存过期","section":"Notes","content":" 缓存的模式 # 参考 # https://hazelcast.com/blog/a-hitchhikers-guide-to-caching-patterns/ "},{"id":2,"href":"/notes/codejam/list/reverse-list/","title":"链表反转","section":"Notes","content":" 链表反转：深入浅出 # 链表反转是什么？ # 链表反转，顾名思义，就是将一个链表的节点顺序颠倒过来。例如，原本的链表是1-\u0026gt;2-\u0026gt;3-\u0026gt;4，反转后就变成4-\u0026gt;3-\u0026gt;2-\u0026gt;1。\n为什么需要链表反转？ # 链表反转是链表操作中一个非常基础且常见的操作，它在很多算法和数据结构中都有应用，比如：\n栈的实现： 链表反转可以用来实现一个栈的数据结构。 队列的实现： 链表反转可以用来实现一个队列的数据结构。 算法优化： 有些算法中，通过链表反转可以优化时间或空间复杂度。 链表反转的实现 # 迭代法 # 迭代法是实现链表反转最常用的方法。其核心思想是：\n初始化三个指针： prev: 指向当前节点的前一个节点 curr: 指向当前节点 next: 指向当前节点的后一个节点 遍历链表： 将 curr 的 next 指针指向 prev，实现反转 将 prev 和 curr 指针都向后移动一位 返回新的头节点： 遍历结束后，curr 指向新的头节点 func reverseList(head *ListNode) *ListNode { // 初始化第一个前驱指针指向null, 即为末端 var prev *ListNode for curr:= head; curr != nil; { // 先用临时指针next保存下一个开始位置 next := curr.Next; // 将当前指针指反转 curr.Next = prev; // 移动指针 prev = curr; curr = next; } return prev; } 递归法 # 递归法是一种更加优雅的实现方式。其核心思想是：\n递归终止条件： 当链表为空或只有一个节点时，直接返回。 递归过程： 递归反转链表的后半部分 将链表的后半部分的头节点的 next 指向当前节点 将当前节点的 next 指向 nullptr ListNode* reverseList(ListNode* head) { if (head == nullptr || head-\u0026gt;next == nullptr) { return head; } ListNode* newHead = reverseList(head-\u0026gt;next); head-\u0026gt;next-\u0026gt;next = head; head-\u0026gt;next = nullptr; return newHead; } 链表反转的复杂度分析 # 时间复杂度： O(n)，其中 n 是链表的长度。无论迭代法还是递归法，都需要遍历链表一次。 空间复杂度： 迭代法： O(1)，只需要常数个额外空间。 递归法： O(n)，递归调用栈的深度最大为 n。 总结 # 链表反转是一个基础且重要的链表操作。通过迭代法和递归法，我们可以实现链表的反转。在选择实现方式时，可以根据具体情况和个人偏好来决定。\n想了解更多关于链表反转的细节吗？ 欢迎提出更多的问题，例如：\n链表反转的具体应用场景有哪些？ 链表反转的优化方法有哪些？ 如何用其他编程语言实现链表反转？ 我也很乐意为你提供更详细的解释和示例代码。\n"},{"id":3,"href":"/notes/iot/rpi/homeassistant/","title":"树莓派和HomeAssistant","section":"Notes","content":" 目标 # 使用开源软件和米家智能硬件，实现简单的智能家居系统\n采用米家智能硬件的原因是, 小米智能家居做的比较早（也许是起初推广的更好，刚接触智能家居的时候就用的小米）, 另外一点是小米智能硬件确实物美价廉，在国外也很受欢迎，Github上也有很多相关项目.\n环境和设备 # RaspberryPi 4 (4GB版本) Ubuntu arm64 树莓派版本 安装HomeAssistant # 这里使用Ubuntu而不是Raspbian的一个原因是Ubuntu官方软件包更新更快（比如raspbian当前为3.7而hass需要3.8+版本)， 且自己笔记本一直用Ubuntu，统一发行版使用起来更加方便\nsudo pip3 install homeassistant 如果下载很慢，可以考虑使用pypi镜像源\n编辑/etc/pip.conf (使用豆瓣源）\n[global] index-url = https://pypi.douban.com/simple 设置开机自启动 # 创建systemd service unit文件 systemctl --user edit --full --force homeassistant.service 加入以下内容\n[Unit] Description=Home Assistant After=network.target [Service] Type=simple ExecStart=/home/ubuntu/.local/bin/hass Restart=on-failure RestartSec=5 [Install] WantedBy=default.target 设置用户自动登录 安装raspi-config, 然后配置 1. System Options -\u0026gt; S5 Boot / Auto Login -\u0026gt; B2 Console Autologin\n会生成/etc/systemd/system/getty@tty1.service.d/autologin.conf, 内容如下\n[Service] ExecStart= ExecStart=-/sbin/agetty --autologin ubuntu --noclear %I $TERM 重启即可生效\n常用设备接入 # 这里主要使用小米硬件设备，开始之前需要获取各个设备的token。参考homeassistant获取miio token的教程\n目前推荐使用云端获取的方式 https://github.com/PiotrMachowski/Xiaomi-cloud-tokens-extractor\n设备协议mihome-binary-protocol\nhomeassistant 参考配置 .homeassistant/configuration.yaml\n# Configure a default setup of Home Assistant (frontend, api, etc) default_config: homeassistant: allowlist_external_dirs: - \u0026#34;/mnt/usb/media\u0026#34; media_dirs: local: /mnt/usb/media # Text to speech tts: - platform: google_translate rpi_camera: image_quality: 100 timelapse: 5000 file_path: /mnt/usb/media/camera/snapshot.jpg group: !include groups.yaml automation: !include automations.yaml script: !include scripts.yaml scene: !include scenes.yaml light: !include lights.yaml yeelight: !include yeelight.yaml remote: !include remote.yaml stream: media_player: !include media_player.yaml device_tracker: !include device_tracker.yaml shell_command: !include shell.yaml telegram_bot: !include telegram.yaml notify: !include notify.yaml 插座/灯泡 # 小米插座chuangmi.plug.m1和灯泡（这里我用的是飞利浦灯泡), 使用[python miio]即可以控制。\n可以在homeassistant管理界面添加Xiaomi Miio集成。\n网关 # 小米网关提供了ZigBee和蓝牙设备接入和管理的功能。\n型号: lumi.gateway.mgl03\n升级官方新版本固件后，不能直接接入。可以刷入第三方固件，然后接入homeassistant。\n刷机 telnet登录网关，按照GitHub上的此教程执行刷机步骤\n如果访问不了Github下载链接，可以使用代理，例如设置环境变量 https_proxy=socks5://192.168.50.60:1080\n红外遥控器 # 红外遥控器也可以使用xiaomi_miio接入homeassistant。\n型号: chuangmi.remote.v2\n配置示例remote.yaml(示例里的raw command我瞎填的, 根据自己的实际需要写）\n- platform: xiaomi_miio name: \u0026#39;chuangmi.remote.v2\u0026#39; host: 192.168.50.72 token: \u0026lt;token\u0026gt; slot: 1 timeout: 30 hidden: false commands: # haier air_conditioner_turn_on: command: - raw:mcwm84lgAkzSazOcSyazScSyYzacTYAhAA3AQ8BjwIfAZ8DfwIfAh8APwA:38400 air_conditioner_turn_off: command: - raw:mcwm84lgAkzSazOcSyazScSyYzacTYAhAA3AQ8BjwIfAQ8BDwO/Bd8APwA/AD8APwA/AD8APwA/AD8AP:38400 air_conditioner_cool: command: - raw:mcwm84lgAkzSazOcSyazScSyYzacTYAhAA3AQ8BjwIfAQ8BDwO/Bd:38400 magic_ball_turn_on: command: - raw:nMxm8wlk0mk2mEsm0ymEsmsxAHKYADlMwB2mgB/ADmBP4B9TGbAYMAR4BFApoBmUxAEMAjwNPA0gJCwcHCI8A/wJ6BjoKrwCOCHuYQA= magic_ball_turn_off: command: - raw:nMxmswlk0mk4mEsm0ymEsmsxAHKYADlNAD+mYA9AL+APUxmwHDTGbAQsAjQAhAdwAhYBCgV2BFoR7g/+Ae01nID/g2cBAYLShH+AjQDXgEJMIAA= 然后我们可以在scripts.yaml里定义常用的操作（这些操作可以在安卓的设备控制器快捷方式找到)\n\u0026#39;air_conditioner_turn_on\u0026#39;: alias: \u0026#39;打开空调(睡眠模式)\u0026#39; sequence: - service: remote.send_command entity_id: \u0026#39;remote.chuangmi_remote_v2\u0026#39; data: command: - \u0026#39;air_conditioner_turn_on\u0026#39; \u0026#39;air_conditioner_turn_off\u0026#39;: alias: \u0026#39;关闭空调\u0026#39; sequence: - service: remote.send_command entity_id: \u0026#39;remote.chuangmi_remote_v2\u0026#39; data: command: - \u0026#39;air_conditioner_turn_off\u0026#39; \u0026#39;air_conditioner_cool\u0026#39;: alias: \u0026#39;空调制冷\u0026#39; sequence: - service: remote.send_command entity_id: \u0026#39;remote.chuangmi_remote_v2\u0026#39; data: command: - \u0026#39;air_conditioner_cool\u0026#39; \u0026#39;magic_ball_turn_on\u0026#39;: alias: \u0026#39;打开小夜灯\u0026#39; sequence: - service: remote.send_command entity_id: \u0026#39;remote.chuangmi_remote_v2\u0026#39; data: command: - \u0026#39;magic_ball_turn_on\u0026#39; \u0026#39;magic_ball_turn_off\u0026#39;: alias: \u0026#39;关闭小夜晚灯\u0026#39; sequence: - service: remote.send_command entity_id: \u0026#39;remote.chuangmi_remote_v2\u0026#39; data: command: - \u0026#39;magic_ball_turn_off\u0026#39; 效果如下\n学习红外码 # 接入遥控器后，我们可以通过它学习红外码。进入开发者工具 -\u0026gt; 服务，选择xiaomi_miio.remote_learn_command\n点击调用服务，然后把遥控器对准米家万能遥控器按下要学习的按键，就可以学习了。识别的红外码会出现在homeassistant 的通知那里, 可以配置到上面yaml的raw command。（在使用前，可以用remote.send_command测以下）\n刚好别人送我一个小夜灯，试了一下，可以智能地控制了。\nHack红外码 # 使用xiaomi_miio.remote_learn_command方式只能学习简单的红外码。对于复杂的红外码，比如空调，遥控器学习识别的红外码不起作用 （我傻乎乎地尝试了好久才发现这个知识）\n解决方式之一是, 你知道空调的各个按键的raw command是什么，即使用红外码库。查了一下，国外有一些开源的红外码库，但没有国内的设备型号， 而且设备类型比较少。\n我使用的是海尔空调，只找到https://github.com/crankyoldgit/IRremoteESP8266库，可能有可以利用的信息（有测试代码）， 但是它使用的是pronto格式，支持的设备类型也有限。\n后面发现了硬核的hack方式, 可以通过串口连上遥控器的控制台，从调试日志中获取红外码。\n这里简单说一下步骤。\n焊接 对于一个新手来说，焊接PCB板是一个比较麻烦的事情。基于大学时，曾焊接制作过一个完整收音机的经历，我开始动手了。\n如图，拆完后焊点是PCB板上的三个圆形金属接触点(TX, RX, GND)。可能不是设计用来焊接的（我猜测应该是有专门的金属探头压在上面，使电路接通），先要将 导线镀焊，不然焊接会颇为麻烦, 不太容易焊上。\nPS, 虽然焊接这个成功了，但是小米台灯焊接后却没能连上， 不过它可以接入到Google Home，作为一个桌面上的台灯也没必要太多的智能控制场景了\n串口调试 连接好USB串口线后，启动电源。\n在笔记本上安装好screen软件, 执行以下命令\nscreen -L /dev/ttyUSB0 115200 # Ctrl + A + : 打开screen菜单 日志将输出到screenlog.0, 随着你在米家App上按下空调键，可以从中看到有用的日志信息(token)。\n这里给出部分日志(被我删除处理过敏感信息了)\n------Now net status:4------ 23:06:44.740 [D] otu: [192.168.50.32:51222] talking, len=32 23:06:44.740 [W] otu: Token private!!. (otu_packet_handle,706) 23:06:44.750 [D] otu: [192.168.50.32:51222] talking, len=32 23:06:44.750 [W] otu: Token private!!. (otu_packet_handle,706) 23:06:44.760 [D] otu: [192.168.50.32:51222] talking, len=32 23:06:44.760 [W] otu: Token private!!. (otu_packet_handle,706) 23:06:44.770 [D] otu: [192.168.50.32:57072] talking, len=304 23:06:44.780 [D] otu: local rpc packet. 23:06:44.780 [D] otu: {\u0026#34;id\u0026#34;: 43, \u0026#34;method\u0026#34;: \u0026#34;miIO.ir_play\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;freq\u0026#34;: 38400, \u0026#34;code\u0026#34;: \u0026#34;mcwm84lgAkzSazOcSyazScSyYzacTYAhAA3AQ8BjwIfAQ8CrwCPAr8APwA/AD8APwA/AD8APwA/AD8APwA/AD8APwA/AD8APwA/AD8APwA\u0026#34;}}. 23:06:44.810 [D] otu: down rpc_local = 7 23:06:44.810 [D] ot: miIO.ir_play found ------do_ir_play cmd:{\u0026#34;id\u0026#34;: 43, \u0026#34;method\u0026#34;: \u0026#34;miIO.ir_play\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;freq\u0026#34;: 38400, \u0026#34;code\u0026#34;: \u0026#34;mcwm84lgAkzSazOcSyazScSyYzacTYAhAA3AQ8BjwIfAQ8CrwCPAr8APwA/AD8APwA/AD8APwA/AD8KDwA/AD8APw6vAh8APwA\u0026#34;}}------ ir_play:Cannot found length Base64Decode------------\u0026gt;len=143 99,cc,26,f3,89,60,2,4c,d2,6b,33,9c,4b,26,b3,49,c4,b2,63,36,9c,4d,80,21,0,d,c0,43,c0,63,c0,87,c0,43,c0,ab,c0,23,c0,af,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,cf,c0,f,c0f,c0,f,c0,f,c0,f,c0,f,c2,27,c0,53,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c0,f,c5,63,c0,f,c0,a3,c0,a3,c8,93,c0,87,e6,33,9,84,c0, Base64Decode------------\u0026gt;end tmp_ct=941 23:06:44.880 [I] user_main: ----origin_code:3078,3078,3078,4,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,1686,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,1686,548,1686,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,1686,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,548,1686,548,548,548,548,548,548,548,548,548,1686,548,548,548,548,548,1686,548,1686,548,548,548,1000 23:06:44.970 [I] splitnums=230 23:06:44.970 [I] item nums=120 last = 1000 wave_data_len=115 ----------------------------- -----send_infrared_fro23:06:m_buf-- len=115 0~2456,1~2456||0~2456,1~3644.990 24||0~432,1~1344||0~432,1~432||0~432,1~1344||0~4[D] otu: {\u0026#34;id\u0026#34;:43,\u0026#34;result\u0026#34;:[\u0026#34;ok\u0026#34;]} 32,1~432||0~432,1~432||0~432,1~1344||0~432,1~1344||0~432,1~432||23:06:45.010 [D] otu 0~432,1~1344||0~432,1~432||0~432,1~1344||0~432,1~1344||0~432,1~1344||0~432,1~1344||0~ 日志中的code部分就是红外码了。\n和来源的作者一样，我这里也告警一下，红外码库可能涉及到授权和购买, 不要用作商业用途和违法事情\nTelegram通知 # 完成了硬件设备的接入，我们还需要实现自动监控和远程控制。\n除了将API托管到云端，还可以通过邮件或者IM工具实现。这里Telegram机器人就可以满足这个需求了。\n配置 # telegram.yaml\n- platform: polling proxy_url: http://127.0.0.1:8118 api_key: \u0026lt;token数字：字符\u0026gt; allowed_chat_ids: - 123456 - platform: broadcast proxy_url: http://127.0.0.1:8118 api_key: \u0026lt;token数字：字符\u0026gt; allowed_chat_ids: - 123456 注意这里使用的是http代理，socks5代理貌似有bug\n接入语音助手 # 天猫精灵 # Google Assistant # 自定义 # UI Icons # https://materialdesignicons.com/icon/air-conditioner\nusage: mdi:air-conditioner\n参考 # HomeAssistant Xiaomi Miio "},{"id":4,"href":"/notes/vim/vim-go/","title":"vim-go","section":"Notes","content":"将VIM打造为Go开发利器\n平时一般使用VSCode编程，最近为了更好地刷leetcode，又换回了vim。发现笔记本小屏幕 使用vscode zen-mode沉浸式看代码很爽以后，也喜欢上了使用vim写代码, 快捷键方便、稳 定高效、功能纯粹（极简主义）。研究了一番后，发现其可行性，便整理了一下。\n主要插件 # 完整列表\nPlug \u0026#39;scrooloose/nerdtree\u0026#39; Plug \u0026#39;preservim/tagbar\u0026#39; Plug \u0026#39;vim-airline/vim-airline\u0026#39; Plug \u0026#39;vim-airline/vim-airline-themes\u0026#39; Plug \u0026#39;fatih/vim-go\u0026#39;, { \u0026#39;do\u0026#39;: \u0026#39;:GoUpdateBinaries\u0026#39; } Plug \u0026#39;Shougo/ddc.vim\u0026#39; Plug \u0026#39;vim-denops/denops.vim\u0026#39; Plug \u0026#39;buoto/gotests-vim\u0026#39; Plug \u0026#39;SirVer/ultisnips\u0026#39; Plug \u0026#39;honza/vim-snippets\u0026#39; vim-go # vim-go是目前主要且流行的针对go的vim插件，视频[Hacking with Andrew and Brad: an HTTP/2 client] (https://www.youtube.com/watch?v=yG-UaBJXZ80)中两位大佬用vim 进行pair编程使用了就是该插件。\nPS: 当时看了这视频后，不禁佩服两位大佬的代码功底，也刷新了使用vim开发实际项目的认知, 原来使用vim写代码 还可以比eclipse/idea/vscode更顺手, 也可以装酷了：》 自己用vim一般也只是用来改改配置，写写简单的脚本，还没尝试过使用它进行正经的项目开发。 虽然以前做过尝试，不过借助vim-go插件和LSP，这成为了真正的可能。\n虽然vim-go原作者已不再参与维护该项目，但已交给社区的另外两人负责，仍然在活跃更新 https://arslan.io/2018/10/09/taking-an-indefinite-sabbatical-from-my-projects/\ngovim govim是一个有意思的vim插件，它尝试使用go语言编写vim插件.\n作为一个后起之秀，它的功能并没有vim-go完善，比如debug功能（这对我来说是一个核心诉求）, 从实际使用体验来看，也不如vim-go稳定。从个人角度而言, vim, go我都喜欢，但使用vim script 编写插件应该有更好的兼容性(vim对go的支持还没有那么的好，对lua和python的支持更佳）, 所以还是选择vim-go插件。\n配置 \u0026#34;.vim/after/ftplugin/go.vim \u0026#34; shortcut like vscode nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;F2\u0026gt; :hide GoRename\u0026lt;CR\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;F4\u0026gt; :hide GoBuild\u0026lt;CR\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;F5\u0026gt; :hide GoDebugStart\u0026lt;CR\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;C-F5\u0026gt; :hide GoRun\u0026lt;CR\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;S-F11\u0026gt; :hide GoDebugStepOut\u0026lt;CR\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;silent\u0026gt; \u0026lt;F12\u0026gt; :hide GoDebugStop\u0026lt;CR\u0026gt; 生成测试方法 # \u0026lsquo;buoto/gotests-vim\u0026rsquo;\n生成测试方法\n:GoTests 默认会生成table-driven测试\nSnippets # \u0026lsquo;honza/vim-snippets\u0026rsquo; \u0026lsquo;Shougo/ddc.vim\u0026rsquo;\n浏览 # \u0026lsquo;scrooloose/nerdtree\u0026rsquo; \u0026lsquo;preservim/tagbar\u0026rsquo;\n类似于vscode, ctrl + B打开或关闭文件概览\n使用F8打开Tagbar（大纲）\nmap \u0026lt;C-b\u0026gt; :NERDTreeToggle\u0026lt;CR\u0026gt; nmap \u0026lt;F8\u0026gt; :TagbarToggle\u0026lt;CR\u0026gt; 安装 # 推荐安装vim 8.2+版本 vim-plug 常用快捷键 # 浏览 # 返回上次位置 Ctrl + O 跳到下一个位置Ctrl + I https://vim.fandom.com/wiki/Jumping_to_previously_visited_locations\n参考 # vim go guide "},{"id":5,"href":"/notes/algorithms/combination-permutation/","title":"排列组合","section":"Notes","content":"This is a testing post for writing markdown with latex\n排列组合 # 独立重复性事件 # \\: n^m # 从n个不同物品中取一个物品，每次取一个，取m次的结果（考虑先后顺序）\nn^m = n \\times n \\times n ... \\times n \\tag 1 \\: A_n^n # 从n个不同物品中取一个物品，每次取一个, 不放回，取n次(完）的结果.（考虑先后顺序）\n第一次有n个结果， 依据独立性事件，第二次有n-1中结果，以此类推\nA_n^n = n(n-1)(n-2)... \\times 2 \\times 1 \\tag 2 \\: A_n^m # 从n个不同物品中取一个物品，每次取一个, 不放回，取m次(可能不取）的结果.（考虑先后顺序），未取到的结果有\\: A_{n-m}^{n-m}种\nA_n^m = \\frac{A_n^n}{A_{n-m}^{n-m}} = n(n-1)(n-2)...(n-m+1) \\tag 3 \\: C_n^m # 从n个不同物品中取一个物品，每次取一个, 不放回，取m次(可能不取）的结果.（不考虑先后顺序）\nC_n^m = \\frac{A_n^m}{A_m^m} = \\frac{n!}{m! \\times (n-m)!} \\tag 4 例子 # 3 * 4 的格子, 从左上走到右下角，只能往下或者往右。\nstart x x x x x x x x x x end 分析： 总步数是固定的往右3步，往下2步, 一共5步， 不需看图，我们知道每一步只需要往前走(往右或往下）即可到达终点。（每行的具体位置确定了，路线就确定了）\n以往下走为例，当往下的两步选定以后（因为是同类型，所以无顺序），路线便确定了，（因为选出的两步都是往下走，没有先后顺序）， 剩余的3步默认生成。\n故其总的走法为\nC_5^2 = \\frac{A_5^2}{A_2^2} = \\frac{5\\times4}{2\\times1} = 10 动态规划 可以使用memory function， 使用一个数组即可\nrecurrence formula:\nf[i,j] = f[i-1,j] + f[i, j-1] for i \u0026gt; 1 and j \u0026gt; 1 f[0,j] = f[i,0] = 1 "},{"id":6,"href":"/notes/linux/linux-cmd-handbook/","title":"Linux Command-line Handbook","section":"Notes","content":"Based on my experiences on Ubuntu\nSoftware Package Management # set up proxy for apt sudo bash -c \u0026#39;cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/apt.conf.d/proxy.conf Acquire { HTTP::proxy \u0026#34;http://127.0.0.1:8118\u0026#34;; HTTPS::proxy \u0026#34;http://127.0.0.1:8118\u0026#34;; } EOF\u0026#39; System Monitoring # Basic Info # # memory free -m # get process id ps aux | grep \u0026lt;pattern\u0026gt; # view startup command of process ps flww -p [PID] # check cpu usage top -p \u0026lt;pid\u0026gt; # list by threads top -H -p \u0026lt;pid\u0026gt; # disk df -h # networks iostat Performance Testing # Network Bindwidth Testing # There are two common means to achive this\nusing iperf (recommended) # server iperf -s # client iperf -c 127.0.0.1 using netcat # server nc -lp 7777 \u0026gt; /dev/null # client pv -r /dev/zero | nc 127.0.0.1 7777 Network # Configuration # set up ip and route for network interface temporarily ifconfig eth0 192.168.0.100 netmask 255.255.255.0 route add default gw 192.168.0.1 # check ip route Drivers # # 查看usb设备 lsusb　# 查看驱动加载日志 dmesg insmod mt76x2u.ko depmod modprobe mt76x2u # remove module rmmod mt76x2u Reference # http://wiki.ubuntu.org.cn/UbuntuSkills http://linuxcommand.org/ The Linux Command Line, Fourth Internet Edition, William Shotts "},{"id":7,"href":"/notes/vim/build-and-install-latest-vim/","title":"VIM安装笔记","section":"Notes","content":" VIM 安装 # 由于debian发行版维护的vim包还未升级到最新版本，但govim需要较高版本的vim。故选择手动编译安装。这里直接选择最新版本8.2， 对应于最新的git tag版本， 8.2版本有一些实用性的功能。\n环境\nUbuntu 19.10 5.3.0-24-generic x84_64 构建及安装过程 # 安装构建工具链 sudo apt update \u0026amp;\u0026amp; sudo apt install -y git build-essential 拉取源码 git clone https://github.com/vim/vim.git # 切换到你想构建的tag git checkout v8.2.0369 开始构建 #cd src #make distclean # if you build Vim before ./configure --with-features=huge \\ --enable-multibyte \\ --enable-python3interp=yes \\ --with-python3-config-dir=$(python3-config --configdir) \\ --enable-perlinterp=yes \\ --enable-luainterp=yes \\ --enable-cscope \\ --prefix=/usr/local make VIMRUNTIMEDIR=/usr/local/share/vim/vim82 sudo apt install checkinstall sudo checkinstall checkinstall执行完后，会安装到/usr/local/bin/vim 即可。\n设置Description Vi IMproved - enhanced vi editor\n将vim设置为默认编辑器 sudo update-alternatives --install /usr/bin/editor editor /usr/local/bin/vim 1 sudo update-alternatives --set editor /usr/local/bin/vim sudo update-alternatives --install /usr/bin/vi vi /usr/local/bin/vim 1 sudo update-alternatives --set vi /usr/local/bin/vim 为了避免重新装回系统vim包，我们可以暂停这个包的apt更新\nsudo apt-mark hold vim 参考链接 # VIM官网构建向导 https://github.com/ycm-core/YouCompleteMe/wiki/Building-Vim-from-source "},{"id":8,"href":"/notes/iot/rpi/fan-and-tempature/","title":"自动控制风扇温度","section":"Notes","content":"最近购买了一个树莓派4B 4G内存版，替换了旧的Model3 (强迫症犯了，就为了换成type c口，但因为电源适配问题还是老老实实地又买了官方电源适配器）\n树莓派4B相对3B性能提高不少，但是随之功耗和发热也上去了。 于是给它整了个金属外壳\n但是依旧烫得厉害，可能是我手动overlock了。开风扇的话，又有点吵，晚上影响睡觉。\n所以又买了一些排线和一个电磁继电器来实现自动通过风扇控制CPU等芯片温度。\n主要原理 # 获取GPU温度 vcgencmd\nvcgencmd measure_temp 获取CPU温度 cpu=$(\u0026lt;/sys/class/thermal/thermal_zone0/temp) echo \u0026#34;$((cpu/1000)) c\u0026#34; 代码实现 # 网上已经有不少python版本的实现，但作为一个go粉，当然选择用go来实现了，正好练习一下gobot包的使用\npackage main import ( \u0026#34;time\u0026#34; \u0026#34;gobot.io/x/gobot\u0026#34; \u0026#34;gobot.io/x/gobot/drivers/gpio\u0026#34; \u0026#34;gobot.io/x/gobot/platforms/raspi\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; ) func main() { low, high := 50, 58 r := raspi.NewAdaptor() sw := gpio.NewDirectPinDriver(r, \u0026#34;18\u0026#34;) work := func() { gobot.Every(5*time.Second, func() { t := readCpuTemp() log.Println(\u0026#34;Temp\u0026#34;, t/1000) if t \u0026lt; low*1000 { sw.Off() } if t \u0026gt; high*1000 { // turn on only ater 7 oclock if h, _, _ := time.Now().Clock(); h \u0026gt; 7 { sw.On() } } }) } robot := gobot.NewRobot(\u0026#34;blinkBot\u0026#34;, []gobot.Connection{r}, []gobot.Device{sw}, work, ) robot.Start() } func readCpuTemp() int { var na = -274150 // set not valid value to -274.15C dat, err := ioutil.ReadFile(\u0026#34;/sys/class/thermal/thermal_zone0/temp\u0026#34;) if err != nil { log.Println(err) return na } s := strings.TrimSuffix(string(dat), \u0026#34;\\n\u0026#34;) t, err := strconv.Atoi(s) if err != nil { log.Println(err) return na } return t } 实现的效果是，当温度高于58度时，启动风扇；温度低于50度时关闭风扇。(风扇一直不停转，大概也只能到45度左右，可能深圳有点热）\n参考 # 树莓派GPIO定义 "},{"id":9,"href":"/posts/diy/cloudcone-save-costs/","title":"使用API管理cloudcone主机","section":"Posts","content":"Cloudcone是2017年成立于美国的一家主机供应商。继vultr变得“不靠谱”和低价vm资源经常“售尽”的情况下，我转而使用cloudcone提供的vps服务用于日常学习和开发。\n除了支持按小时计费、提供更换IP服务及支持支付宝/paypal等灵活的支付方式外，我最看重的是，它的价格能做到真正的弹性，即在vm关机状态不计费CPU/内存等费用,比online费用大概减半。\n类似于其他云供应商平台，cloudcone还提供了开放的API来管理云主机。\n这里为了方便使用和合理控制资源，自己便用go写了一个小程序\n代码实现 # 主要逻辑如下，通过cloudcone 提供的API。每天晚上23左右关机，次日早晨7点左右启动 如果调用失败的话，会再次重试一次。(如果依然不行的话，就当运气不好了:\u0026lt;）\n以下是草稿版本代码\nsecret.go package main var ( // 配置相关信息,这里我填写的是假的啦 serverID = 123456 appSecret = \u0026#34;Q2aQr9323QE233r2\u0026#34; hashCode = \u0026#34;zXqV22222222222222222222222222222222225bL\u0026#34; ) serverID可以在compute菜单控制面板下查看，或查看浏览器url里的参数。\nappSecret和hashCode访问https://app.cloudcone.com/user/api创建即可。\nmain.go /* * cloudcone api https://api.cloudcone.com/ */ package main import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/robfig/cron\u0026#34; ) // CloudconeResponse represents the API Response type CloudconeResponse struct { Status int Message string Data interface{} `json:\u0026#34;_data\u0026#34;` } const ( baseAPIURL = \u0026#34;https://api.cloudcone.com/api/v1\u0026#34; ) var ( client = \u0026amp;http.Client{} ) func main() { f, err := os.OpenFile(\u0026#34;app.log\u0026#34;, os.O_RDWR|os.O_CREATE|os.O_APPEND|os.O_TRUNC, 0644) if err != nil { log.Fatalf(\u0026#34;Error while opening file: %v\\n\u0026#34;, err) } defer f.Close() log.SetOutput(f) wg := sync.WaitGroup{} _, cancel := context.WithCancel(context.Background()) c := cron.New() // boot at 07:00 c.AddFunc(\u0026#34;0 0 7 * * *\u0026#34;, func() { log.Println(\u0026#34;booting at time\u0026#34;, time.Now()) if err := boot(); err != nil { log.Println(err) time.Sleep(15 * time.Second) // try again boot() } }) // shutdown at 23:45 c.AddFunc(\u0026#34;0 45 23 * * *\u0026#34;, func() { log.Println(\u0026#34;Shutdown at time\u0026#34;, time.Now()) if err := shutdown(); err != nil { log.Println(err) time.Sleep(15 * time.Second) // try again shutdown() } }) c.Start() wg.Add(1) go func() { defer wg.Done() os.Stdin.Read(make([]byte, 1)) // wait for Enter keystroke c.Stop() cancel() // cancel the associated context }() log.Println(\u0026#34;Running...\u0026#34;) wg.Wait() } func boot() error { // compute/:id/boot endpoint := fmt.Sprintf(\u0026#34;%s/compute/%d/%s\u0026#34;, baseAPIURL, serverID, \u0026#34;boot\u0026#34;) req, err := http.NewRequest(\u0026#34;GET\u0026#34;, endpoint, nil) if err != nil { return err } req.Header.Set(\u0026#34;App-Secret\u0026#34;, appSecret) req.Header.Set(\u0026#34;Hash\u0026#34;, hashCode) resp, err := client.Do(req) if err != nil { return err } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { return err } fmt.Println(string(body)) var dat CloudconeResponse if err := json.Unmarshal(body, \u0026amp;dat); err != nil { return err } if dat.Status != 1 { return errors.New(dat.Message) } log.Println(dat.Message) return nil } func shutdown() error { // compute/:id/shutdown endpoint := fmt.Sprintf(\u0026#34;%s/compute/%d/%s\u0026#34;, baseAPIURL, serverID, \u0026#34;shutdown\u0026#34;) req, err := http.NewRequest(\u0026#34;GET\u0026#34;, endpoint, nil) if err != nil { return err } req.Header.Set(\u0026#34;App-Secret\u0026#34;, appSecret) req.Header.Set(\u0026#34;Hash\u0026#34;, hashCode) resp, err := client.Do(req) if err != nil { return err } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { return err } var dat CloudconeResponse if err := json.Unmarshal(body, \u0026amp;dat); err != nil { return err } if dat.Status != 1 { return errors.New(dat.Message) } log.Println(dat.Message) return nil } 参考 # cloudcone中文介绍 "},{"id":10,"href":"/notes/web/yarn/","title":"Yarn","section":"Notes","content":"Yarn是Facebook、Google等主导开发的新的Javascript包管理器。（相对于npm)\n安装 # sudo npm install -g yarn --registry https://registry.npm.taobao.org 这里使用了taobao npm镜像\n配置Angular Cli使用yarn 使用ng命令设置全局使用yarn\nng config -g cli.packageManager yarn 使用 # 添加依赖\nyarn add \u0026lt;DEP_NAME\u0026gt; # dev yarn add -D \u0026lt;DEP_NAME\u0026gt; 参考工具自带帮助文档\nyarn --help 包下载缓存 # 可以通过设置环境变量YARN_CACHE_FOLDER来指定缓存目录\nUbuntu下修改~/.bashrc\necho \u0026#39;YARN_CACHE_FOLDER=$HOME/.yarn\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 构建速度简单比较 # 使用项目tour-of-heroes安装nodejs依赖。\n镜像: https://registry.npm.taobao.org\nNPM (6.14.5) Yarn (1.22.4) real\t0m26.231s real 0m14.048s user\t0m31.685s user\t0m15.415s sys\t0m5.247s sys\t0m5.666s 可以看到yarn明显要快一些。 类似于npm安装依赖时创建package-lock.json文件，yarn也会创建yarn.lock文件锁定依赖。（这时安装已有包换registry会不生效)\n包下载镜像 # SASS_BINARY_SITE=https://npm.taobao.org/mirrors/node-sass/ PHANTOMJS_CDNURL=https://npm.taobao.org/mirrors/phantomjs/ ELECTRON_MIRROR=https://npm.taobao.org/mirrors/electron/ 可以自己搭建一个镜像，解决内网防火墙内无法下载包的问题\n使用Caddy反向代理taobao镜像 :8080 { # https://npm.taobao.org/mirrors/node-sass/ route /dist/node-sass/* { reverse_proxy https://cdn.npm.taobao.org { header_up Host {http.reverse_proxy.upstream.hostport} } } # https://npm.taobao.org/mirrors/phantomjs/ reverse_proxy /dist/phantomjs/* https://cdn.npm.taobao.org { header_up Host {http.reverse_proxy.upstream.hostport} } } node-sass 离线安装 下载地址 https://github.com/sass/node-sass/releases\n# 设置环境变量，注意使用绝对路径 export SASS_BINARY_PATH=\u0026lt;absolute_path_to_file\u0026gt; "},{"id":11,"href":"/notes/cloud-native/k8s/container-dev-on-win10/","title":"win10下的应用容器化开发","section":"Notes","content":"相对于Linux对容器化开发的良好支持（或者说各个容器化平台和工具对Linux更好的支持），在Windows下对应用进行容器化改造时的本地构建和测试并不是很直接和方便。这里记录一下，针对不同场景的相关实践经验。\n目标 # 支持docker构建 支持kubernetes容器服务编排 WSL # WSL (Windows subsystem for Linux) 是win10新增的一个功能，可以直接在Windows上运行本机Linux命令工具。之前大家一般会去用Cgwin (或MingGw)工具。\nWSL 提供一个名为 Bash.exe 的应用程序，启动该应用程序后，会打开一个运行 Bash shell 的 Windows 控制台。 使用 Bash 可以运行命令行 Linux 工具和应用。\n具体介绍可以参考微软提供的WSL文档。\nWSL1 并没有一个完整的Linux内核，系统调用使用Windows Pico进程使用驱动翻译成NT API模拟成Linux内核的。具体架构可以参考WSL的系统架构。\n最近更新的WSL引入了微软提供的一个完整的Linux内核，增强了文件IO性能及完整的系统调用兼容性。这也意味着我们可以通过WSL2以Linux中的方式运行docker和kubernetes （这里我们使用microk8s)。\nWindows下可直接使用WSL里Linux命令， 如netstat -an | wsl grep :8443, 在pipe后面加上wsl即可\n适用场景 # 版本要求\nWin10 Version 2004, Build 19041 + （目前需要加入每月更新的预览版计划）\nHyper V支持 （需要Windows支持，同时需要设备支持硬件虚拟化)\n优点 # 与Windows命令窗口和文件系统无缝集成，开发起来十分方便。在当前窗口输入bash就可以进入Linux下对应的目录；同时还有VSCode Remote WSL的支持。\n安装配置 # 启用Hyper V和Linux子系统\nEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux -NoRestart Enable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform 然后重启\n下载安装最新的WSL2 Linux内核并安装, 参考https://docs.microsoft.com/en-us/windows/wsl/wsl2-kernel\n设置默认WSL版本为2\nwsl --set-default-version 2 从微软商店下载安装Ubuntu 20.04 LTS.\n安装完毕后，启动Ubuntu Bash, 初始化相应配置。\n因为wsl没有pid为1的进程，所以systemd无法使用。这里snapcraft论坛给出了一个解决办法\n# Create the starting script for SystemD vi /etc/profile.d/00-wsl2-systemd.sh SYSTEMD_PID=$(ps -ef | grep \u0026#39;/lib/systemd/systemd --system-unit=basic.target$\u0026#39; | grep -v unshare | awk \u0026#39;{print $2}\u0026#39;) PWD=$(pwd) if [ -z \u0026#34;$SYSTEMD_PID\u0026#34; ]; then sudo /usr/bin/daemonize /usr/bin/unshare --fork --pid --mount-proc /lib/systemd/systemd --system-unit=basic.target SYSTEMD_PID=$(ps -ef | grep \u0026#39;/lib/systemd/systemd --system-unit=basic.target$\u0026#39; | grep -v unshare | awk \u0026#39;{print $2}\u0026#39;) fi if [ -n \u0026#34;$SYSTEMD_PID\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;$SYSTEMD_PID\u0026#34; != \u0026#34;1\u0026#34; ]; then exec sudo /usr/bin/nsenter --wd=\u0026#34;$PWD\u0026#34; -t $SYSTEMD_PID -a su $LOGNAME fi 然后就可以按照官方文档安装docker和用snap命令安装microk8s了。\nTip: 如果00-wsl2-systemd.sh出现错误，可以使用用管理员打开cmd窗口执行bash -c \u0026quot;vim /etc/profile.d/00-wsl2-systemd.sh\u0026quot;方式编辑修改解决 （可以通过该方法修改，但无法删除文件）\nmultipass # multipass可以在各个操作系统平台，使用系统内置虚拟化管理程序（如hyper-v, virtualbox)，提供一个mini云平台。\n适用场景 # 在开发设备构建类似于生产的云环境 需要设备支持硬件虚拟化 优点 # 适用范围广，能在本地的开发设备上迅速构建一个便于使用的云环境。\n安装配置 # 从它的github发布页面下载最新版本https://github.com/canonical/multipass/releases.\n启用hyper-v或者安装virtualbox, 默认使用hyper-v，如果使用virtualbox，需要执行下面的命令\nmultipass set local.driver=virtualbox 启动一个primary实例\nmultipass launch --name primary 在实例中执行命令\nmultipass exec primary -- bash # 或者 multipass shell 使用multipass mount命令可以将本地文件mount到虚拟机，使用multipass transfer命令可以在宿主机和虚拟机之间传输文件。具体参考https://multipass.run/docs\n远程连接 # docker和kubernetes都支持远程连接方式控制，除了在本地安装docker/kubernetes外，我们可以选择在服务器上安装好docker/kubernetes，然后配置好远程连接，在windows上像本地一样使用容器服务\n适用场景 # 本地无法安装docker/kubernetes服务 需要与其他开发者共享容器化服务 安装配置 # docker -\u0026gt; 开启服务和证书 https://docs.docker.com/engine/security/https/\nkubernetes -\u0026gt; kubeconfig文件\n参考 # https://docs.microsoft.com/en-us/windows/wsl/install-win10 https://wsl.dev/wsl2-microk8s/ https://multipass.run/docs/installing-on-windows "},{"id":12,"href":"/notes/cloud-native/k8s/helm.zh/","title":"Helm","section":"Notes","content":"这里我们使用helm 3.0+版本, 可以直接使用kube-server api, 不需要在集群安装tiler\n安装 # sudo snap install helm --classic Chartmuseum # repo: https://github.com/helm/chartmuseum\n本地安装\ncurl -LO https://s3.amazonaws.com/chartmuseum/release/latest/bin/linux/amd64/chartmuseum chmod +x chartmuseum sudo mv chartmuseum /usr/bin/ sudo mkdir /opt/chart \u0026amp;\u0026amp; sudo chown $USER /opt/chart ./chartmuseum --storage=local --storage-local-rootdir=/opt/chart 然后打开http://localhost:8080就可以看到欢迎界面\n创建和使用chart # 我们以创建一个nginx chart为例。\n使用helm创建初始化配。\nmkdir app helm create chart 然后可以看到初始化的以下配置\nartificerpi@ky-laptop:~/build/app$ tree chart chart ├── charts ├── Chart.yaml ├── templates │ ├── deployment.yaml │ ├── _helpers.tpl │ ├── ingress.yaml │ ├── NOTES.txt │ ├── serviceaccount.yaml │ ├── service.yaml │ └── tests │ └── test-connection.yaml └── values.yaml 3 directories, 9 files 修改chart/Chart.yaml文件，将name字段改为nginx-foo\npackage\nhelm package . install\nhelm install \u0026lt;NAME\u0026gt; foo-0.1.0.tgz 安装helm-push插件\nhelm plugin install https://github.com/chartmuseum/helm-push.git 加入本地chartmuseum仓库\nhelm repo add chartmuseum http://localhost:8080 推送nginx-foo chart\nhelm push chart/ chartmuseum # 或者指定版本 helm push chart/ chartmuseum --version=0.1.1 成功后，通过curl命令调用chartmuseum api就可以看到上传结果\n# curl http://localhost:8080/api/charts {\u0026#34;nginx-foo\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;nginx-foo\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;0.1.0\u0026#34;,\u0026#34;description\u0026#34;:\u0026#34;A Helm chart for Kubernetes\u0026#34;,\u0026#34;apiVersion\u0026#34;:\u0026#34;v2\u0026#34;,\u0026#34;appVersion\u0026#34;:\u0026#34;1.16.0\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;application\u0026#34;,\u0026#34;urls\u0026#34;:[\u0026#34;charts/nginx-foo-0.1.0.tgz\u0026#34;],\u0026#34;created\u0026#34;:\u0026#34;2020-04-03T10:26:49.059906306+08:00\u0026#34;,\u0026#34;digest\u0026#34;:\u0026#34;aa6532c71a1a463d34d295f4c9a36bafbcd116e4520c8661af9fd13773f0b7b8\u0026#34;}]} 示范 # all in one helm chart\nsonarqube\nspring boot app with web frontend\n"},{"id":13,"href":"/notes/cloud-native/cicd/jenkinsx.zh/","title":"JenkinsX","section":"Notes","content":"Jenkins是一款比较经典而优秀的流水线构建工具（平台）。\n为了实现现代化构建方式Run configuration as Code, Jenkins引入了Blue Ocean插件。通过该插件，我们可以使用声明式语法来编写Jenkinsfile，定义流水线构建步骤 https://www.jenkins.io/zh/doc/book/pipeline/jenkinsfile/\n然而在云原生和DevOps越来越流行的今天，传统的Jenkins模式只能满足CI的构建需求。于是Jenkins团队又引入了JenkinsX, 来实现一个现代化的GitOps平台。\nemm, 不吹水了，其实我只想做个笔记,记录下折腾了很久后的才明白的安装步骤\n目标 # 使用jx工具在microk8s上安装jenkinsx\nhttps://jenkins-x.io/docs/labs/\n因为不喜欢使用helm2在k8s上安装tiller, 所以这里直接跳级到helm3。不过这里就要使用JenkinsX Lab里的jxl工具了。(目前是实验性版本的jenkinsx，意味着要花更多时间折腾)\n结果：暂时弃坑了，直接上tektoncd\n安装 # jxl本身使用gitops方式维护JenkinsX集群\njxl 安装 # 从这个链接下载安装jxl工具 https://github.com/jenkins-x-labs/jxl/releases\n创建仓库 # jxl boot create 这里我们选择minikube，和microk8s应该差不多。(注意不要选择更新本地jx版本，至少这篇文章写的时候这一步还有bug)\n按提示输入完毕就会初始化仓库，把jenkins bot的token记录下来, 我偷懒直接用这个访问github 私有仓库（开起了两步验证，直接使用密码没有办法直接推代码到github)\n这里还有一步是设置secret, 建议使用Hashicorp Vault存储secrets信息。 安装启动 # 拉取远程配置启动 jxl boot run --git-url https://github.com/artificerpi/environment-jx-dev --git-user artificerpi --git-token \u0026lt;TOKEN\u0026gt; 本地启动 （只是一个测试） cd environment-jx-dev \u0026amp;\u0026amp; jxl boot run -b 目前无法运行起来，报错/secrets/jx-boot/secrets.yaml无法找到，可能是个bug\nerror: failed to load secrets YAML /secrets/jx-boot/secrets.yaml: open /secrets/jx-boot/secrets.yaml: no such file or directory "},{"id":14,"href":"/notes/web/caddy/","title":"Caddy与http3","section":"Notes","content":" Caddy 简单介绍 # Caddy是现代化的web代理服务器，使用Go语言编写，不直接依赖系统底层库。 另外，它很好地支持了https (也最先支持了http3), 而且它使用了现代化流行且安全的配置，几乎不需要额外配置。\n安装使用 # 我们可以去官网下载2.0版本 https://caddyserver.com/ 我们只需要拿到二进制文件即可。\n下载后放到/usr/local/bin/caddy, 然后编辑Caddyfile\n/etc/Caddyfile\n{ # debug servers { protocol { experimental_http3 } } } www.mwine.science { # redirect www.mwine.science to mwine.science redir https://mwine.science{uri} } mwine.science { root * /var/www/html/mwine.science file_server encode zstd gzip } 配置参考 https://caddyserver.com/docs/caddyfile/options\n这里我将域名mwine.science和www.mwine.science绑定到了同一台服务器，并将www.mwine.science重定向到mwine.science\n然后创建一个文件/var/www/html/mwine.science/index.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; Hello World ! \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 最后运行起来就可以了 （这里我加上了watch选项，启用根据文件配置动态更新）\n/usr/local/bin/caddy run -config /etc/Caddyfile -watch 或者我们可以将它写成systemd服务，输入命令编辑sudo systemctl edit --force --full caddy.service\n粘贴以下内容\n[Unit] Description=Caddy server daemon Wants=network-online.target After=network.target network-online.target multi-user.target [Service] ExecStart=/usr/local/bin/caddy run -config /etc/Caddyfile -watch Restart=on-failure RestartSec=30 TimeoutStopSec=30 [Install] WantedBy=multi-user.target 酱紫就完成了, 然后你就有了一个http3的网站！\n这意味着什么？ （薅羊毛）\nhttp3内置了tls1.3, 所以网站的安全性大大提升了，而且更快（具体可以了解http3协议） DNS解析可以使用Cloudflare去实现，毕竟他家宣称有最快的1.1.1.1 DNS服务器 (当然还有其他功能呢） 然后TLS证书哪里来的？ 实际上caddy自动帮你完成了Let's Encrypt证书服务的接入和更新，可以通过日志查看。 而它们都是免费的！\n"},{"id":15,"href":"/notes/go/setup-go/","title":"Go安装","section":"Notes","content":"官方下载安装向导请参考这里https://golang.org/dl/\n这篇文章主要分享加速访问go依赖和资源站点的问题。\n环境 # Ubuntu 19.10 x86_64 版本号 go1.14 linux/amd64 下载安装 # Go安装文件可以访问国内站点 https://golang.google.cn/dl/\n解压后，移动到/usr/local/go目录，然后在/etc/profile里加入\nexport GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin 使用技巧 # goproxy # 使用goproxy加速go module下载(解决go get无法下载来自golang.org等站点的依赖包的问题）\n参考https://goproxy.io/zh/, 在go 1.13+下，我们可以使用以下命令在go env设置goproxy\ngo env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.io,direct # 设置不走 proxy 的私有仓库，多个用逗号相隔（可选） go env -w GOPRIVATE=*.corp.example.com 同样推荐使用国内站点https://goproxy.cn/\n文档查看 # 使用go doc命令可以在终端快速查阅文档, 例如 go doc net.Listen | vim - 参考 # "},{"id":16,"href":"/notes/cloud-native/k8s/k8s-get-started/","title":"Kubernetes使用入门","section":"Notes","content":" 容器化 Containerization # 容器是标准化的软件单元。容器化将软件打包成标准化的单元，从而能够以此进行开发，装载和部署。简单地说，通过底层虚拟化，容器化实现应用Write once, run anywhere， 而且是快速地run anywhere，就像docker图标里被鲸鱼背着的集装箱一样。\n容器与虚拟机的对比 # 容器实现的是操作系统层面的虚拟化，而虚拟机是实现硬件层面的虚拟化。所以对于应用来说，选择容器会更加轻量级，这意味着它将占用更少的资源，能更快的启动和停止，更灵活地分配资源等等。\nPS: 这里并不是说容器一定总比虚拟机好，一般来说，不同的技术方案都有它适应的场景。比如我们需要模拟完整的硬件环境，虚拟机方案显然就更合适了。例如，在办公电脑上，我常常在windows笔记本上使用hyper-v安装一个ubuntu做开发，容器化方案在这里就相形见绌了。\n很多时候，容器和虚拟机被一起使用。比如，你买了一台性能很好的高可用服务器，1TB RAM, 64 core CPU，那么为了更合理的分配和管理资源，你可能首先在这台服务器上建立数个virtualbox虚拟机，然后再在虚拟机操作系统里安装docker。\n容器编排 # 容器化是我们能更方便地打包和运行应用，但当需要运行成百上千或者更多容器的时候，容器的自动化管理就十分重要了。对于习惯于实现应用自动化的程序员来说，甚至只管理两三个容器就巴不得有一个工具来完成自动化。容器编排就是来解决这个问题的，比较流行的有Google开发并开源的kubernetes, 及docker官方推的docker swarm。前者几乎已经成为业界规范，不过docker swarm对docker集成的更好，如果熟悉docker的话，docker swarm也会更加容易上手。\n容器编排常见的功能 （不想翻译)\nExpose containers by DNS name or IP address. Handle load balancing and traffic distribution for containers. Automatically mount local and cloud-based storage. Allocate specific CPU and RAM resources to containers and then fit them onto nodes. Replace or kill problematic containers without jeopardizing application performance and uptime. Manage sensitive information like password and tokens without rebuilding containers. Change the state of containers and roll back old containers to replace them with new ones. 参考 # 什么是容器化 容器化的优点 什么是container 安装 # docker 安装 # 不推荐使用系统源或者snap包方式安装docker, 使用的时候会遇到环境或者兼容性的问题。\n推荐使用docker官方源进行安装 https://docs.docker.com/install/\nKubernetes 安装 # 这里我们在本地学习使用kubernetes, 可以选择microk8s\n如果没有安装snapd，可以参考以下内容安装\nhttps://snapcraft.io/docs/installing-snapd\nsudo snap install microk8s --classic 配置 # 网络设置 sudo ufw allow in on cni0 \u0026amp;\u0026amp; sudo ufw allow out on cni0 sudo ufw default allow routed PS: 这里如果漏了先执行这一步，可能会导致容器之间网络访问不通 常见错误为dial tcp 10.152.183.1:443: i/o timeout 其实执行ufw default allow routed的时候已经提示了已生成的iptables规则需要手动更新\nDefault routed policy changed to \u0026#39;allow\u0026#39; (be sure to update your rules accordingly) 这里我直接采用简单暴力的方式解决（全部刷新重建）\nsudo microk8s.stop sudo ufw disable sudo iptables -F sudo iptables -X sudo iptables -P INPUT ACCEPT sudo iptables -P FORWARD ACCEPT sudo iptables -P OUTPUT ACCEPT sudo ufw enable sudo microk8s.start 用户环境配置 sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube sudo snap alias microk8s.kubectl kubectl 启动 sudo microk8s.start sudo microk8s status --wait-ready # 检查是否成功 sudo microk8s.inspect 配置kubeconfig，默认情况下helm等工具使用$HOME/.kube/config作为KUBECONFIG文件访问k8s api, microk8s在把它存放在$SNAP_DATA目录下\nkubectl config view --raw \u0026gt;~/.kube/config 代理设置 # Docker服务代理设置 # 我们可以通过给docker daemon设定http代理环境变量来使用代理。\n例如如果使用的是http代理（https类似）,可以创建/etc/systemd/system/docker.service.d/http-proxy.conf 文件，并添加以下内容：\n[Service] Environment=\u0026#34;HTTP_PROXY=http://127.0.0.1:8118/\u0026#34; \u0026#34;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\u0026#34; 参考https://docs.docker.com/config/daemon/systemd/\nmicrok8s 代理 # 编辑/var/snap/microk8s/current/args/containerd-env文件，按照文件里的向导，设置好HTTPS_PROXY环境变量，使用命令sudo systemctl restart snap.microk8s.daemon-containerd.service重启生效。\n参考https://microk8s.io/docs/install-proxy\ncontainerd # microk8s 使用containerd替换了原来使用的docker，参考https://github.com/ubuntu/microk8s/commit/7c3311a6d24a0eae482dc09e86471ead41aaa19e PS: docker engine现在也是使用containerd。\n不过microk8s使用的containerd为microk8s.containerd 服务，不与apt方式安装的共用sock文件，因此docker pull下来的images microk8s不能直接使用。\n我们可以使用containerd手动导入镜像解决该问题（microk8s下载docker镜像比较慢，我们也可以先使用docker下载，然后用microk8s.ctr倒入）\n# save image as tar file # docker save k8s.gcr.io/pause:3.1 \u0026gt; pause.tar https_proxy=socks5://192.168.50.1:1080 microk8s.ctr image pull docker.io/calico/cni:v3.23.5 # the cri plugin is using the k8s.io namespace microk8s.ctr --namespace k8s.io image import pause.tar kubernetes相关概念 # 试一试 # 安装好kubernetes后，类似于docker run命令，我们可以使用简单的命令立即启动一个pod。\ndocker run --name whoami containous/whoami:latest kubectl run --image=containous/whoami:latest whoami 简单地介绍k8s # 这里我们仅以应用开发者的角度简单地介绍kubernetes。\nPod # Pod为描述应用程序的\u0026quot;逻辑主机\u0026quot;进行建模，一个pod可以包含一个或多个相对耦合的容器。在同一个Pod里的容器，他们的许多资源是共享的，甚至可以使用标准IPC通信。\n一个Pod永远只运行在一个节点上。\nkubernetes定义了一系列的Controllers (控制器）来的定义和管理Pod.\nReplicaSet ReplicationController Deployments StatefulSets DaemonSet Garbage Collection TTL Controller for Finished Resources Jobs - Run to Completion CronJob 我们比较（直接）常用到的是Deployment。根据其名字可以看到它的使用场景和应用部署密切相关，比如创建部署、回滚、更新状态、暂停部署等。\n以下是一个nginx应用示例 （kubernetes的服务编排一般可以通过yaml声明定义）\nnginx-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:stable ports: - containerPort: 80 部署\nkubectl apply -f nginx-deployment.yaml # 查看 # kubectl get deployments 参考\nhttps://kubernetes.io/docs/concepts/workloads/pods/pod/ https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-intro/ https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ Service # Service将运行在一组Pods上的某个应用抽象为一个服务。kubernetes还集成了服务发现和服务代理来保证服务的高可用性。\nnginx-service.yaml apiVersion: v1 kind: Service metadata: name: nginx-service spec: selector: app: nginx ports: - protocol: http port: 8080 targetPort: 80 使用kubectl apply后，可以得到以下服务\nartificerpi@ky-laptop:~/build/nginx$ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 104m nginx-service ClusterIP 10.152.183.39 \u0026lt;none\u0026gt; 8080/TCP 2m37s # curl http://10.152.183.39:8080 Ingress # Ingress是一个管理外部如何对服务进行访问的API对象，将外部请求路由到kubernetes集群里的服务。也可以理解为内部服务向外暴露。 internet |\n[ Ingress ] [ Services ] 一般由Ingress Controller来实现各种Ingress需求，通常Ingress controller也是一个负载均衡器(Load banlancer)，比如Kong，Traefik，ingress-nginx等。\nKubernetes组建库本身没有集成安装Ingress Controller，但一般的云供应商会提供该产品，当然也可以选择上面提到的几个开源方案。 一般云供应商提供的Ingress Controller会集成ISP网络服务给service分配外部IP，这里本地开发测试的话，我们可以使用traefik 或者metalb https://metallb.universe.tf/\nNamespace 命名空间 # 通过namespace定义，Kubernetes支持多租户模式使用。\napiVersion: v1 kind: ServiceAccount metadata: namespace: traefik name: traefik-ingress-controller 参考\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/ ServiceAccount 服务帐号 # 服务账户为 Pod 中运行的进程提供了一个标识。通过服务帐号和权限配置（如RBAC）, 我们可以保证应用在集群的安全性。 结合namespace的作用, 就算不同的用户(或应用）在同一个kubernetes集群中，也能做好应用隔离和保证服务安全性。\n如果要进一步学习请参考官方文档 https://kubernetes.io/docs/concepts/\n参考 # https://kubernetes.io/zh/blog/2019/11/26/%E4%BD%BF%E7%94%A8-microk8s-%E5%9C%A8-linux-%E4%B8%8A%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C-kubernetes/ https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/ pull "},{"id":17,"href":"/notes/dev/make-gradle-work-with-eclipse/","title":"Make Eclipse Great Again","section":"Notes","content":" Eclipse \u0026amp; Gradle # 还是从那句老话开始， “工欲善其事，必先利其器”。要想熟练地完成一件事，有个好的工具往往能事半功倍。\n但是很多时候，迷信教条最终会成了造轮子而造轮子的递归循环；选择合适的工具，并掌握它，解决好问题才是正确的方向。\n这里简单说说，我选择Eclispe和Gradle的原因。\nGradle (Gradle VS Maven or Ant); 选择gradle的原因很简单，简单而清晰的语法，强大的脚本语言，快速而稳定的构建。\nEclipse (主要对比Idea, VS Code)\n开源及活跃而广受欢迎的社区 相对于Idea来说，个人使用经验上来看，在大Project上使用（源码多，项目多）更稳定, 且有偏向支持开源社区的因素，故使用Eclipse；VS Code对于小的Project来说还好，功能比Eclipse弱，查看多个文件及源码也不是很方便，大项目会使系统卡顿，但是小项目一般可以使用gradle + vim。 开发环境 # 当前开发环境\nUbuntu 19.10 x86_64 Gradle 5.6.4 Eclipse (Snap版本) Eclipse Platform Version: 2019-03 (4.11) Build id: I20190307-0500 OS: Linux, v.5.3.0-24-generic, x86_64 / gtk 3.24.12 Java version: 1.8.0_171 Eclipse项目配置及依赖管理 # 我的Java项目管理方案 # 我不喜欢将IDE文件提交到git代码仓库，在我看来，IDE的作用就是一个文本编辑器，而且从协作角度来看，不同的开发者可能会选择不同的编辑器，所以不需要将IDE文件提交。 而Gradle脚本，不仅作为项目开发中一款重要的工具，而且包含了很多项目配置信息，因此需要提交到git仓库(有时候，如果开发人员和CI使用了统一的或兼容的gradle版本，甚至gradle wrapper都不需要提交)\n生成项目配置 默认Gradle eclipse编译输出目录为bin, 但是gradle构建输出目录为build， 因此需要改配置。\nplugins { id \u0026#39;java\u0026#39; id \u0026#39;eclipse\u0026#39; } eclipse { project.natures \u0026#39;org.eclipse.buildship.core.gradleprojectnature\u0026#39; classpath { downloadJavadoc = true downloadSources = true defaultOutputDir = file(\u0026#39;build/default\u0026#39;) file.whenMerged { entries.each { source -\u0026gt; // This seems kludgy. If the second test is omitted, it fails processing a \u0026#39;Project Dependency\u0026#39; entry if (source.kind == \u0026#39;src\u0026#39; \u0026amp;\u0026amp; source.hasProperty(\u0026#39;output\u0026#39;)) { def outputPath = source.output switch(source.path) { case \u0026#39;src/main/java\u0026#39;: source.output = \u0026#39;build/classes/java/main\u0026#39; break case \u0026#39;src/main/resources\u0026#39;: source.output = \u0026#39;build/resources/main\u0026#39; break case \u0026#39;src/test/java\u0026#39;: source.output = \u0026#39;build/classes/java/test\u0026#39; break case \u0026#39;src/test/resources\u0026#39;: source.output = \u0026#39;build/resources/test\u0026#39; break } } } } } } https://github.com/gradle/gradle/issues/3839\nGradle BuildShip插件 # UT 命令方式\ngradle test --tests a.b.c.d.ClassA.methodX IDE方式\n测试结果可以通过下图方式查看，具体错误信息点击show failure就可以看到。\nDebug 命令方式， 需要远程debug。使用--debug-jvm命令监听socket端口，默认5005, 然后使用Eclipse attach上就可以了。\ngradle test --debug-jvm --tests a.b.c.d.ClassA.methodX 或者直接用IDE Debug As \u0026ndash;\u0026gt; Gradle Test就可以了\n刷新依赖 # gradle eclipse --refresh-dependencies 解决IDEA 无法刷新snapshot依赖\nconfigurations.all { resolutionStrategy.cacheDynamicVersionsFor 10, \u0026#39;minutes\u0026#39; resolutionStrategy.cacheChangingModulesFor 10, \u0026#39;minutes\u0026#39; } 自动刷新 # 因为SringBoot的“hotreload”方案并不是真正的热部署（动态类加载机制），所以这里就称它为自动刷新。\n这里主要需要改动的是，将eclipse默认输出目录bin改为build, 对应于gradle java插件默认构建输出目录。参考上面配置，然后勾选Project -\u0026gt; Build automatically 就可以了。\n对于代码量比较大，但是机器性能不佳的情况，请酌情考虑，否则太卡影响开发工作。\n掌握必要的快捷键 # 熟悉常用快捷键能迅速提高开发效率，不用键盘和鼠标切来切去，影响敲代码。而且当Eclipse很卡时，快捷键相比鼠标移动能降低资源消耗。 参考 https://github.com/artificerpi/devbox/blob/master/ide/eclipse.md\n"},{"id":18,"href":"/notes/linux/mt7612u-driver/","title":"Ubuntu下使用MT7612U","section":"Notes","content":"由于墙挡住了路由器WIFI信号，虽然5G频率的WIFI传输速率很快，但是信号衰减。WIFI无线通信是双方向的，就算路由信号能覆盖到，但考虑到手机或笔记本功率和天线的限制，难保证信号稳定。所以在淘宝上买了一个功能还算强大的无线网卡ComFast 926AC v2，双频WIFI外置双天线。没提前研究，“号称免驱动\u0026quot;，结果拿回来就懵了。\n安装驱动 # 设备: Comfast 926AC v2 系统： Ubuntu 18.04\n因为是联发科的芯片，通常都是在同一份驱动代码上改改完成的。故从github上寻找了下面两个仓库的代码。\nulli-kroll/mt7612u, jurobystricky/Netgear-A6210 官方驱动\n上面两驱动实际是在官方源码上改写的，但编译后，三个都不能正常工作。\n后来在openwrt/linux项目下发现该设备驱动的相关issue, 并已有大牛正在mt76驱动项目下加入该芯片的支持。故转用mt76的设备。查询linux主仓库代码发现，该驱动已随Linux内核5.0发布。因此直接下载linux 5.0内核包安装就行了。\n# 5.0: https://kernel.ubuntu.com/~kernel-ppa/mainline/v5.0/ linux-headers-5.0.0-050000_5.0.0-050000.201903032031_all.deb linux-headers-5.0.0-050000-generic_5.0.0-050000.201903032031_amd64.deb linux-image-unsigned-5.0.0-050000-generic_5.0.0-050000.201903032031_amd64.deb linux-modules-5.0.0-050000-generic_5.0.0-050000.201903032031_amd64.deb 手动升级内核后测试能使用, 并支持AP：\niwconfig\nwlx40a5eff2b655 IEEE 802.11 ESSID:off/any Mode:Managed Access Point: Not-Associated Tx-Power=19 dBm Retry short limit:7 RTS thr:off Fragment thr:off Power Management:off 网卡识别为存储设备的问题 mt76还未对这款comfast网卡适配，所以默认会被系统识别为存储设备，可以手动切换过来：\nsudo usb_modeswitch -KW -v 0e8d -p 2870 或者修改/lib/udev/rules.d/40-usb_modeswitch.rules文件自动切换（目前未成功）\n# MT7612U ATTR{idVendor}==\u0026#34;0e8d\u0026#34;, ATTR{idProduct}==\u0026#34;2870\u0026#34;, RUN+=\u0026#34;usb_modeswitch \u0026#39;%b/%k\u0026#39;\u0026#34; USB底座接触不良的问题 一起买的底座有点问题，开始还以为也要装什么驱动。检查后发现是接触不良的问题，因为USB口没有固定住，所以网卡很容易没有插入到底座中。解决办法比较简单，拆卸底座，然后填充底座中空部分，固定住USB接口。\n其他适配问题 网卡的LED灯不能正常工作。\npi@raspberrypi:~ $ sudo ifconfig wlan1 down pi@raspberrypi:~ $ sudo ifconfig wlan1 hw ether 00:28:C7:0A:42:A2 pi@raspberrypi:~ $ sudo ifconfig wlan1 up 尝试在树梅派上编译驱动 # 4.19.y已经加入mt7612u的支持，但是经过测试，并不能使用。[更新] 在5.1.y上编译可以正常使用（STA模式）, 注意默认缺失了/lib/firmware/mt7662.bin /lib/firmware/mt7662_rom_patch.bin 两个文件，可以从其它系统拷贝或网络下载到树梅派。\n[ 247.230807] usb 1-1.5: new high-speed USB device number 5 using dwc_otg [ 247.362296] usb 1-1.5: New USB device found, idVendor=0e8d, idProduct=7612, bcdDevice= 1.00 [ 247.362311] usb 1-1.5: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [ 247.362321] usb 1-1.5: Product: 802.11ac WLAN [ 247.362331] usb 1-1.5: Manufacturer: MediaTek Inc. [ 247.362342] usb 1-1.5: SerialNumber: 000000000 [ 247.620811] usb 1-1.5: reset high-speed USB device number 5 using dwc_otg [ 247.752088] mt76x2u 1-1.5:1.0: ASIC revision: 76120044 [ 247.773734] mt76x2u: probe of 1-1.5:1.0 failed with error -22 [ 247.773857] usbcore: registered new interface driver mt76x2u 安装过程：\n首先更新内核版本 高版本内核可能要求4.15以上才可以直接升级，所以先使用rpi-update升级到最新版本内核(4.19.y) # 这里也把rpi-update一起装了 sudo apt-update \u0026amp;\u0026amp; sudo apt install -y rpi-update rpi-source # 执行升级 sudo rpi-update # 如果使用rpi-update升级后又回退过，可能不能再次使用rpi-update升级回来 # Trick: 更改/boot/.firmware_revision然后，再次执行rpi-update sudo reboot 拉取源码 rpi-source # 链接到build sudo ln -s `pwd`/linux-789277d012f4a9ba1b032c298c3ebe2db5d91835 /lib/modules/$(uname -r)/build 安装工具 sudo apt-get install git bison flex libssl-dev bc libncurses5-dev 生成编译配置 KERNEL=kernel7 make bcm2709_defconfig # menuconfig来配置，默认disable了mt76x2, (先用斜杠搜索mt76菜单，再进入，可以上下翻页) make menuconfig 开始编译 #-j4 分配到4个核来编译 make -j4 zImage modules dtbs 安装 sudo make modules_install sudo cp arch/arm/boot/dts/*.dtb /boot/ sudo cp arch/arm/boot/dts/overlays/*.dtb* /boot/overlays/ sudo cp arch/arm/boot/dts/overlays/README /boot/overlays/ sudo cp arch/arm/boot/zImage /boot/$KERNEL.img # reboot Tips： 编译来自三方源码的驱动：\ncd \u0026lt;PATH-TO-DRIVER-SRC\u0026gt; make -C /lib/modules/$(uname -r)/build M=$pwd modules 其他问题解决 # dhcp， 使用时碰到了无法从路由器获取ipv4地址的情况，可以设置dhcp加入新的wlan1网络接口,并注意设置好DNS，否则会影响上网\nip route 默认的ip route可能会出错或者wlan1优先级低而不能正常接入网络作中继。参考以下可以工作的配置\npi@raspberrypi:~ $ ip route show default via 192.168.0.1 dev wlan1 src 192.168.0.129 metric 305 192.168.0.0/24 dev wlan1 proto kernel scope link src 192.168.0.129 metric 305 192.168.21.0/24 dev wlan0 proto kernel scope link src 192.168.21.1 metric 303 设置iptables\nsudo iptables -t nat -A POSTROUTING -o wlan1 -j MASQUERADE 这里我使用网络中继的主要原因是只将只能设备接入树梅派发射的局域网而不是直接接入到路由器上。\n参考 # https://github.com/ulli-kroll/mt7612u/issues/27 https://github.com/torvalds/linux/commit/cac97ed681db9891c74be91b54e6b550dc6afb03 https://www.raspberrypi.org/documentation/linux/kernel/building.md "},{"id":19,"href":"/notes/cloud-native/cicd/drone-ci-with-github/","title":"Drone CI With Github","section":"Notes","content":"Yeah, another CI tool. That\u0026rsquo;s named Drone.\nWe\u0026rsquo;ve been heard of Jenkins, travis-ci and even circle-ci (I have to mention this because there\u0026rsquo;re too much ads on youtube for it), so why would we need another one?\nI\u0026rsquo;ve used Jenkins and travis-ci, but they are not perfect, at least there are some slight drawbacks.\nMy experience on Jenkins # Jenkins is stable for production, it has long history and is used widely. But sometimes I find Jenkins is too slow, and configuration is not straightforward. And it\u0026rsquo;s a pain to upgrade to a new pipeline, you have to copy and paste jobs from UI (while accessing is pretty slow). You might able to config jobs with XML config files, but it\u0026rsquo;s still a bit of complicated.\nIf you don\u0026rsquo;t use containers in Jenkins, workspaces will take too much storage when there are too many jenkins jobs. This will make you have to expand the storage disk one day.\nSome teams may use old version of Jenkins with some bugs, but they are not willing to upgrade it because of the risks of workload and technical problems.\nMy Experience Travis-CI # Faster than Jenkins Lighter UI Configuration as Code Need to learn the configuration grammer \u0026hellip; What about Drone? # Lighter and elegant UI Configuration is straightforward, syntax just like docker-compose Ship Code Fast Container Native \u0026hellip; So it\u0026rsquo;s just like the upgrading path: Jenkins -\u0026gt; travis-ci -\u0026gt; drone-ci. The latter one seems absorb the advantages and make it better.\nBut drone is not totally free to use: https://discourse.drone.io/t/licensing-and-subscription-faq/3839\nThough it\u0026rsquo;s licensed under apache 2.0 license for oss use, you may never use the oss version because it\u0026rsquo;s lack of agent support and its functions are limited.\nBut it\u0026rsquo;s free to use for open source projects. See license. While Jenkins and travis are under MIT license.\nDrone Cloud # In 2018/11/27 Drone Cloud was announced, and it\u0026rsquo;s free for open source. see https://blog.drone.io/drone-cloud/.\nSetting up with github (public repo) # Preparement # GitHub token [repo] A created public project Sample configuration for golang project: goserve\nworkspace: base: /go path: src/github.com/artificerpi/goserve steps: - name: test image: golang pull: always commands: - go test -v ./... - name: build image: golang pull: always commands: - go get github.com/mitchellh/gox - go get -t -v ./... - gox -output=\u0026#34;./dist/{{.Dir}}_{{.OS}}_{{.Arch}}\u0026#34; -os=\u0026#34;linux darwin windows\u0026#34; -arch=\u0026#34;amd64\u0026#34; -verbose ./... when: event: - push - tag - name: publish image: plugins/github-release settings: api_key: from_secret: github_token files: dist/* checksum: - sha256 when: event: tag # ... Here we declare the workspace and set gopath, and we use gox to do cross-platform buliding, and finally publish the release with plugin github-release to relase artifacts.\nRelease artifacts # share artifacts with another step Note that we can directly use the artifacts by the build step, no need to do volume mount (for security, mouting is not availbe on public drone cloud)\napi key Here we read the secret from an environment var github_token, which is configured in the UI of drone in project settings.\nOne more java project sample from here: java-sample\n"},{"id":20,"href":"/notes/cloud-native/cicd/jiri.zh/","title":"Jiri","section":"Notes","content":"Jiri (/jɪəri/ YEER-ee)是谷歌工程师开发的，灵活集成多个git仓库的工具，主要用来管理fuchsia操作系统源码。\n其主要功能类似于git submodule, 但使用方式更加灵活，不需要对原git仓库的行为做任何修改，也可以不用在主仓库不断更新引用。\n安装 # 推荐从源码编译安装 (需要安装最新版本Go语言构建工具）\ngit clone https://fuchsia.googlesource.com/jiri cd jiri/cmd/jiri/jiri go build # go install sudo mv jiri /usr/local/bin/jiri Manifest # manifest (文件名称为foo) \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;projects\u0026gt; \u0026lt;project name=\u0026#34;spring-petclinic-mybatis\u0026#34; remote=\u0026#34;https://github.com/artificerpi/spring-petclinic-mybatis\u0026#34; path=\u0026#34;backend\u0026#34;/\u0026gt; \u0026lt;project name=\u0026#34;spring-petclinic-angular\u0026#34; remote=\u0026#34;https://github.com/spring-petclinic/spring-petclinic-angular.git\u0026#34; path=\u0026#34;frontend\u0026#34;/\u0026gt; \u0026lt;/projects\u0026gt; \u0026lt;/manifest\u0026gt; 将此文件放到git仓库根目录下，本地创建目录foo\nmkdir foo \u0026amp;\u0026amp; cd foo jiri init # manifest repos jiri import foo https://github.com/artificerpi/jiri-foo jiri update 更多使用参考下面的文档和help命令\n参考 # https://fuchsia.googlesource.com/jiri/ "},{"id":21,"href":"/posts/hugo/math-in-markdown/","title":"Math in Markdown","section":"Posts","content":" LaTeX # Configuration # I prefer to configure formular delimiters with the way using brackets:\ninline: \\(...\\) display: \\[...\\] display + equation number: \\[...\\] (1) For vscode, install extension Markdown+Math, then change Configuration from dollars into brackets. For mathJax, it\u0026rsquo;s provided in the default configuration.\nGood memory is not as bad as a pen.\nPermutation # A_n^n=n\\times(n-1)\\times(n-2)\\times...\\times2\\times1\nA_n^m=n\\times(n-1)\\times(n-2)\\times...\\times(n-m+1) = \\frac{n!}{(n-m)!}\nCombination # C_n^m=\\frac{A_n^m}{A_m^m} = \\frac{n!}{m!(n-m)!}\nC_n^m=C_n^{n-m} C_{n+1}^{r+1} = C_n^r + C_n^{r+1}\nBinomial theorem # (a+b)^n = \\sum_{i=0}^n{{C_n^i}a^{n-i}b^i} \\tag 1 2^n =\\sum_{i=0}^n{{C_n^i}} = C_n^0 + C_n^1 + C_n^2 + ... + C_n^n\nVSCode Plugin # https://marketplace.visualstudio.com/items?itemName=goessner.mdmath\nHugo # see mathjax_support.html\nand replace cmd {{ replaceRE \u0026quot;\\\\[ (.*) \\\\]\u0026quot; \u0026quot;\u0026amp;bsol;[ $1 \u0026amp;bsol;]\u0026quot; .Content | safeHTML }} to fix markdown escape backslash problem.\nproblem to be solved equation number problem\necho \u0026#34;Hello World\u0026#34; \\begin{equation} E=m \\end{equation}\n\\begin{equation} E=m \\end{equation} Reference # https://en.wikibooks.org/wiki/LaTeX/Mathematics https://marketplace.visualstudio.com/items?itemName=goessner.mdmath "},{"id":22,"href":"/notes/iot/rpi/rpi-4g-lte-module/","title":"树莓派4G模块","section":"Notes","content":" 准备环境 # 树莓派3B 华为4G模块：HUAWEI ME909s-821 PCIE转USB开发板 5cm天线转接线，SMA公头外螺内孔 吸盘天线全向高增益天线，SMA公头外螺内孔 中国移动4G SIM卡 4G模块技术规格及文档 # 技术规格 连接 基于海思芯片, 同类比较 SIM7600CE (Qualcomm MDM9206)\n文档 连接 主天线M口\n开始使用 # Windows上使用该4G模块需要手动安装驱动，驱动连接\nUbuntu下可以使用modemmanager管理4G模块\n树莓派下使用教程如下。\n查看usb设备是否被识别 lsusb # output: Bus 001 Device 004: ID 12d1:15c1 Huawei Technologies Co., Ltd. Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. SMC9514 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub 安装拨号软件 sudo apt-get update sudo apt-get install ppp usb-modeswitch wvdial 初始化wvdial配置 sudo wvdialconf /etc/wvdial.conf 修改wvdial配置 [Dialer Defaults] Init1 = ATZ Init2 = ATQ0 V1 E1 S0=0 Init3 = AT+CGDCONT=1,\u0026#34;IP\u0026#34;, \u0026#34;cmnet\u0026#34; Modem Type = Analog Modem Baud = 9600 New PPPD = yes Modem = /dev/ttyUSB0 ISDN = 0 Phone = *99***1# Password = { } Username = { } Auto DNS = on APN和拨号设置参考\n国内运营商 APN 拨号 移动 at+cgdcont=1,\u0026ldquo;ip\u0026rdquo;,\u0026ldquo;cmnet\u0026rdquo; *99***1#或*98*1# 联通 at+cgdcont=1,\u0026ldquo;ip\u0026rdquo;,\u0026ldquo;3gnet\u0026rdquo; *99# 电信 at+cgdcont=1,\u0026ldquo;ip\u0026rdquo;,\u0026ldquo;ctnet\u0026rdquo; #777 开始拨号 pi@raspberrypi:~ $ sudo wvdial --\u0026gt; WvDial: Internet dialer version 1.61 --\u0026gt; Initializing modem. --\u0026gt; Sending: ATZ ^S +23806F8RE 2C , ^2/ ATZ OK --\u0026gt; Sending: ATQ0 V1 E1 S0=0 ATQ0 V1 E1 S0=0 OK --\u0026gt; Sending: AT+CGDCONT=1,\u0026#34;IP\u0026#34;, \u0026#34;cmnet\u0026#34; AT+CGDCONT=1,\u0026#34;IP\u0026#34;, \u0026#34;cmnet\u0026#34; OK --\u0026gt; Modem initialized. --\u0026gt; Sending: ATDT*99***1# --\u0026gt; Waiting for carrier. ATDT*99***1# CONNECT 150000000 --\u0026gt; Carrier detected. Waiting for prompt. --\u0026gt; Don\u0026#39;t know what to do! Starting pppd and hoping for the best. --\u0026gt; Starting pppd at Tue Nov 27 22:14:54 2018 --\u0026gt; Pid of pppd: 1690 --\u0026gt; Using interface ppp0 --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; local IP address 10.50.126.214 --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; remote IP address 10.64.64.64 --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; primary DNS address 221.179.38.7 --\u0026gt; pppd: �`�[01]�W�[01] --\u0026gt; secondary DNS address 120.196.165.7 --\u0026gt; pppd: �`�[01]�W�[01] 打开另一个窗口测试网络 curl https://www.raspberrypi.org/ 查看信号质量 cat /dev/ttyUSB0 \u0026amp; echo -e \u0026#34;AT+CSQ\\r\\n\u0026#34; \u0026gt; /dev/ttyUSB0 AT+CSQ语法\n命令解释：检查网络信号强度 命令格式：AT+CSQ\u0026lt;CR\u0026gt; 命令返回：+CSQ: **, ## 其中： **应在 0 到 31 之间（99表示无信号），数值越大表明信号质量越好； ##为误码率，值在 0 到 99 之间。否则应检查天线或 SIM 卡是否正确安装 计算公式：信号强度 = -113dBm + (rssi * 2)\n测试结果：\nAT+CSQ\u0026lt;CR\u0026gt; +CSQ: 31, 99 优化配置 # 解决等待输入命令的问题 --\u0026gt; Carrier detected. Waiting for prompt. # Systemd Service Unit文件\n[Unit] Description=4G LTE Modem daemon After=multi-user.target [Service] ExecStart=/usr/bin/wvdial --config /etc/wvdial.conf PIDFile=/var/run/lte-modem.pid KillMode=process Restart=on-failure RestartSec=10 [Install] WantedBy=multi-user.target 在/etc/wvdial.conf中加入Stupid Mode = on选项，参考这里。\nAP和以太网路由设置 # AP参考之前的文章，这里主要说以太网路由 (LTE -\u0026gt; 以太网接口)\n设置eth0为静态IP 方式1：\n设置静态IP\n# vim /etc/network/interfaces.d/eth0 auto eth0 allow hot-plug eth0 iface eth0 inet static address 172.24.1.1 netmask 255.255.255.0 gateway 172.24.1.1 修改dhcpcd管理eth0\necho \u0026#34;denyinterfaces eth0\u0026#34; \u0026gt;\u0026gt; /etc/dhcpcd.conf 方式2：（动态配置，推荐）\nsudo ifconfig eth0 172.24.1.1 netmask 255.255.255.0 broadcast 172.24.1.1 配置dnsmasq作为dhcp服务器 # vim /etc/dnsmasq.d/dnsmasq-eth0.conf interface=eth0 listen-address=172.24.1.1 bind-interfaces server=8.8.8.8 domain-needed bogus-priv dhcp-range=172.24.1.2,172.24.1.50,12h 动态配置\ndnsmasq --interface=eth0 --except-interface=wlan0 --bind-interfaces --conf-file=/dev/null --dhcp-range=172.24.1.2,172.24.1.100,12h iptables规则 # 增加 #iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE iptables -A FORWARD -i ppp0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT iptables -A FORWARD -i eth0 -o ppp0 -j ACCEPT 便携式4G LTE # 几年前入手了一个4G modem, 外观同这个 http://vonger.cn/?p=14785\n在openwrt上没有成功，USB设备驱动无法被识别， 在笔记本 Ubuntu上成功使用，脚本(参考了这里https://github.com/gartfr/QualcommLTE)\n使用如下脚本启动成功\n#!/bin/bash if [ ! \u0026#34;$(lsusb -d \u0026#39;161c:f010\u0026#39;)\u0026#34; ]; then printf \u0026#34;usb not plugged\\n\u0026#34; ; fi # switch from mass storage to modem devices sudo usb_modeswitch -v 161c -p f010 -W -M 55534243123456780000000000000606f50402527000000000000000000000 sudo modprobe qmi_wwan sudo bash -c \u0026#39;echo \u0026#34;161c f101\u0026#34; \u0026gt; /sys/bus/usb/drivers/qmi_wwan/new_id\u0026#39; sleep 2 BUS_ID=$(lsusb -d \u0026#39;161c:f101\u0026#39; | cut -d \u0026#39; \u0026#39; -f2 | tr -d 0) export FIRST_PORT_ID=$(ls /sys/bus/usb/drivers/qmi_wwan/ | grep \u0026#34;${BUS_ID}-*.0\u0026#34;) export SECOND_PORT_ID=$(ls /sys/bus/usb/drivers/qmi_wwan/ | grep \u0026#34;${BUS_ID}-*.1\u0026#34;) # 这里usb ID通过dmesg或`lsusb -t`查看， 先禁用在启用1.1是因为默认无法正确加载驱动 sudo bash -c \u0026#34;echo \u0026#39;${FIRST_PORT_ID}\u0026#39; \u0026gt; /sys/bus/usb/drivers/qmi_wwan/unbind\u0026#34; sudo bash -c \u0026#34;echo \u0026#39;${SECOND_PORT_ID}\u0026#39; \u0026gt; /sys/bus/usb/drivers/qmi_wwan/unbind\u0026#34; sleep 1 sudo bash -c \u0026#34;echo \u0026#39;${SECOND_PORT_ID}\u0026#39; \u0026gt; /sys/bus/usb/drivers/qmi_wwan/bind\u0026#34; sleep 1 sudo modprobe option sudo bash -c \u0026#34;echo \u0026#39;161c f101\u0026#39; \u0026gt; /sys/bus/usb-serial/drivers/option1/new_id\u0026#34; # mmcli --list-modems # sudo ip route delete default # sudo ip route add default dev ppp0 该类型设备一般自带windows驱动程序，插上自动安装就可以使用。但是在linux下需要适配驱动，也需要将usb设备从cd-rom模式切换为LTE。 拆开后，发现4G通信模块芯片为Qualcomm MDM9215。通过windows下驱动设备的状态可以识别到切换为LTE的product id 为f101\n谷歌搜索后获取到这个设备的modem切换信息 https://github.com/NetworkManager/usb_modeswitch-data/blob/master/usb_modeswitch.d/1c9e:f010 (message信息从这里获取的）\n然后尝试使用qmi_wwan驱动后，成功了。\n注意，启动失败后需要清理环境。杀死所有子进程，否则再次启动拨号会失败。\n关于天线 https://zhuanlan.zhihu.com/p/51098683 类似modem教程 https://github.com/gartfr/QualcommLTE modem学习资料 http://trac.gateworks.com/wiki/wireless/modem ubuntu modem-manager (modem clit替代wvdial拨号, 推荐使用network-manager建立网卡接口) https://core.docs.ubuntu.com/en/stacks/network/modem-manager/docs/configuring-cellular-connections 参考 # https://www.thefanclub.co.za/how-to/how-setup-usb-3g-modem-raspberry-pi-using-usbmodeswitch-and-wvdial https://blog.csdn.net/qq_32384313/article/details/77725235 https://www.findhao.net/easycoding/2114.html "},{"id":23,"href":"/notes/linux/vbox-ubuntu-server/","title":"Vbox Ubuntu Server","section":"Notes","content":" Virtualbox with Ubuntu Server # Manage Virtualbox in command line\nInstallation # sudo apt install virtualbox # or manually # wget https://download.virtualbox.org/virtualbox/5.2.22/virtualbox-5.2_5.2.22-126460~Ubuntu~bionic_amd64.deb # sudo dpkg -i virtualbox*.deb Install extenstion pack # sudo apt install virtualbox-ext-pack # or manually # sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-5.2.4-119785.vbox-extpack # check installation VBoxManage list extpacks Create VM # Create virtual disk VBoxManage createmedium disk --filename ubuntu-server1.vdi --size 8192 Create virtual machine VBoxManage list ostypes | grep -B 1 -A 2 Ubuntu VBoxManage createvm --name ubuntu-server1 --ostype \u0026#34;Ubuntu_64\u0026#34; --register Configure virtual machine # add sata disk VBoxManage storagectl ubuntu-server1 --name SATA --add sata --controller IntelAHCI VBoxManage storageattach ubuntu-server1 --storagectl SATA --port 0 --device 0 --type hdd --medium ubuntu-server1.vdi # mount dvd bootable iso file VBoxManage storagectl ubuntu-server1 --name IDE --add ide VBoxManage storageattach ubuntu-server1 --storagectl IDE --port 0 --device 0 --type dvddrive --medium ~/Downloads/mini.iso VBoxManage modifyvm ubuntu-server1 --ioapic on VBoxManage modifyvm ubuntu-server1 --boot1 dvd --boot2 disk --boot3 none --boot4 none VBoxManage modifyvm ubuntu-server1 --memory 512 --vram 8 VBoxManage modifyvm ubuntu-server1 --nic1 nat Set for VRDE (optional) VBoxManage setproperty vrdeextpack \u0026#34;Oracle VM VirtualBox Extension Pack\u0026#34; # vrde port 5000, 5010, 5011 or 5012 VBoxManage modifyvm ubuntu-server1 --vrde on --vrdeport 5000,5010-5012 Start vm VBoxManage startvm ubuntu-server1 --type headless VBoxManage showvminfo ubuntu-server1 Test it rdesktop -a 16 -N \u0026lt;HOST-IP\u0026gt;:\u0026lt;PORT\u0026gt;\nDetach iso file after os installation VBoxManage storageattach ubuntu-server1 --storagectl IDE --port 0 --device 0 --type dvddrive --medium none Take snapshot VBoxManage snapshot ubuntu-server1 take \u0026lt;SNAPSHOT-NAME\u0026gt; VBoxManage snapshot ubuntu-server1 restore \u0026lt;SNAPSHOT-NAME\u0026gt; show vm info vboxmanage showvminfo \u0026lt;VM Name\u0026gt; Network # Host-only Network # VBoxManage hostonlyif create VBoxManage list hostonlyif VBoxManage hostonlyif remove vboxnet1 Common scripts # startvm.sh #!/bin/bash vms=( ubuntu-server1 ubuntu-server2 ubuntu-server3 ) for vm in ${vms[*]}; do VBoxManage startvm ${vm} --type headless done stopvm.sh #!/bin/bash vms=( ubuntu-server1 ubuntu-server2 ubuntu-server3 ) for vm in ${vms[*]}; do echo ${vm} VBoxManage controlvm ${vm} poweroff done set-vrde.sh #!/bin/bash vms=( ubuntu-server1 ubuntu-server2 ubuntu-server3 ) for i in $( seq 1 3 ); do VBoxManage modifyvm \u0026#34;ubuntu-server${i}\u0026#34; --vrde on --vrdeport \u0026#34;500${i}\u0026#34; done rdp.sh #!/bin/bash for i in $( seq 1 3 ); do printf \u0026#34;connect to: 127.0.0.1:500${i}\\n\u0026#34; rdesktop -a 16 -N -T \u0026#34;ubuntu-server${i}\u0026#34; \u0026#34;127.0.0.1:500${i}\u0026#34; \u0026amp; done MacOS on virtualbox # setup scripts VBoxManage modifyvm \u0026#34;macOS\u0026#34; --cpuidset 00000001 000106e5 00100800 0098e3fd bfebfbff VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal/Devices/efi/0/Config/DmiSystemProduct\u0026#34; \u0026#34;iMac11,3\u0026#34; VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal/Devices/efi/0/Config/DmiSystemVersion\u0026#34; \u0026#34;1.0\u0026#34; VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal/Devices/efi/0/Config/DmiBoardProduct\u0026#34; \u0026#34;Iloveapple\u0026#34; VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal/Devices/smc/0/Config/DeviceKey\u0026#34; \u0026#34;ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc\u0026#34; VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal/Devices/smc/0/Config/GetKeyFromRealSMC\u0026#34; 1 VBoxManage setextradata \u0026#34;macOS\u0026#34; \u0026#34;VBoxInternal2/EfiGraphicsResolution\u0026#34; \u0026#34;1920x1080\u0026#34; Reference: https://www.virtualbox.org/wiki/Mac%20OS%20X%20build%20instructions\nTroubleShouting # https://askubuntu.com/questions/465454/problem-with-the-installation-of-virtualbox https://help.ubuntu.com/community/Installation/MinimalCD https://help.ubuntu.com/community/Installation/SystemRequirements https://www.virtualbox.org/manual/ch07.html https://www.perkin.org.uk/posts/create-virtualbox-vm-from-the-command-line.html https://www.virtualbox.org/manual/ch08.html "},{"id":24,"href":"/posts/diy/root-your-android-phone/","title":"怎样安全地Root你的安卓手机","section":"Posts","content":"出于各种原因，我们可能会对自己手机上的安卓系统并不满意，而Root是我们DIY自己的安卓机的一把钥匙。\n注意手机Root后并不一定安全，本文仅仅说的是用安全（较为透明公开）的方式自己root你的手机。\n但安全永远是相对的，如果你对手机ROOT后的安全性有较大顾虑，请不要进行该操作。\n对ROOT后的设备，也请远离流氓软件和恶意网站，尽可能使用可信度高的应用与服务。\n预先准备 # MagiskManager Twrp APK文件从谷歌商店下载 sdk与fastboot工具 win linux mac 准备一台PC和数据线，能使用开发者模式调试安卓手机 解锁你的手机 # 打开开发者模式 打开设置 -\u0026gt; 关于手机 -\u0026gt; 软件信息 -\u0026gt; 内部版本号 -\u0026gt; 一直点它\n启用OEM解锁 进入开发者选项，勾选允许OEM解锁。 注意OEM解锁会清空手机数据，如果要进行下去请备份号手机数据。\n另外，解锁后，部分手机开机启动后会有一个源自安卓系统的安全警告画面，若不喜欢也建议不要继续。\n准备Magisk文件 # 在Magisk的Github发布页面下载apk程序进行安装，按照应用提示，下载最新的Magisk文件\nOEM 解锁 # 将adb和fastboot加入环境变量\n对windows用户而言，解压缩platform-tools_rx.x.x-windows.zip文件，进入解压缩后的文件夹，根目录后下会显示有adb.exe和fastboot.exe等文件。 然后将光标移到文件夹空白处，同时按下Shift键和鼠标右键，点击弹出来的菜单选项，打开命令窗口（后续操作需要在此进行，请不要关闭）。\n检查能PC检测到连入的手机\nadb kill-server \u0026amp;\u0026amp; adb start-server adb devices 重启手机进入download模式\nadb reboot download 解锁bootloader\nfastboot oem unlock fastboot flashing unlock 刷入twrp到Recovery # 在download模式中刷入recovery\nfastboot flash recovery twrp.img fastboot reboot recovery 刷入Magisk文件 # 在上述步骤完成进入recovery后，可以看到twrp的一些管理菜单，选择安装我们刚才下载的magisk zip文件， 完成后重启手机。\n定制自己的ROM（极客，需要熟悉一些计算机程序知识） # 推荐一个工具来完成 https://github.com/artificerpi/android_system_extraction_and_repack_tool\n参考 # https://twrp.me/htc/htcu11.html "},{"id":25,"href":"/notes/iot/vocore/my-vocore-playground/","title":"我的DIY与vocore","section":"Notes","content":" VoCore # 硬币大小的Linux计算机（或者可以DIY的mini路由器）\n技术参数 # Target: ramips Subtarget: mt7628 Package architecture: mipsel_24kc OpenWRT techdata 具体参数请看官网介绍 VoCore2 Ultimate 和 openwrt列出的技术数据\nOpenWRT介绍 # OpenWRT(与LEDE合并后更名为OpenWrt)是一个适用于嵌入式设备的Linux发行版，最初由Linksys公司推出的WRT-54G无线路由中使用的Linux系统开源而来。相比于路由器原厂固件而言，OpenWRT提供了一个可添加软件包的可写文件系统，这样用户就能自己定制路由器的功能。基于开放的生态和良好的技术社区环境，OpenWRT十分适合喜好DIY的科技粉来定制自己的路由器。\nOpenWRT主要使用opkg来管理软件包，默认使用LuCI作为web交互界面。下面简单列出它们的常用方式，具体使用方法请查阅文档。\nopkg\n# 安装软件包 opkg install \u0026lt;PACKAGE-NAME\u0026gt; # 卸载软件包 opkg remove \u0026lt;PACKAGE-NAME\u0026gt; uci\n# 设置option uci set \u0026lt;OPTION\u0026gt; # 查看option uci show \u0026lt;OPTION\u0026gt; 我的定制 # 基本设置 # Change SSID Name uci set wireless.ap.ssid=\u0026#39;firefly\u0026#39; uci commit # check result uci show wireless.ap.ssid # restart networking service to make reload configuration /etc/init.d/network restart # check network in another machine sudo iw dev wlan0 scan | grep SSID wget ssl # opkg install libustream-openssl ca-bundle ca-certificates AP+STA模式 （或者叫无线中继器） # 使用固件 vocore2-20180723V 配置信息(仅供参考)：\nuci show wireless\nwireless.ra0=wifi-device wireless.ra0.type=\u0026#39;ralink\u0026#39; wireless.ra0.variant=\u0026#39;mt7628\u0026#39; wireless.ra0.country=\u0026#39;CN\u0026#39; wireless.ra0.channel=\u0026#39;auto\u0026#39; wireless.ra0.disabled=\u0026#39;0\u0026#39; wireless.ra0.hwmode=\u0026#39;11g\u0026#39; wireless.ap=wifi-iface wireless.ap.device=\u0026#39;ra0\u0026#39; wireless.ap.mode=\u0026#39;ap\u0026#39; wireless.ap.network=\u0026#39;lan\u0026#39; wireless.ap.ifname=\u0026#39;ra0\u0026#39; wireless.ap.ssid=\u0026#39;“放大后”的WIFI-名称\u0026#39; wireless.ap.key=\u0026#39;密码不告诉你:)\u0026#39; wireless.ap.encryption=\u0026#39;psk2\u0026#39; wireless.sta=wifi-iface wireless.sta.device=\u0026#39;ra0\u0026#39; wireless.sta.mode=\u0026#39;sta\u0026#39; wireless.sta.network=\u0026#39;wwan\u0026#39; wireless.sta.ifname=\u0026#39;apcli0\u0026#39; wireless.sta.key=\u0026#39;密码不告诉你:)\u0026#39; wireless.sta.disabled=\u0026#39;0\u0026#39; wireless.sta.encryption=\u0026#39;psk2\u0026#39; wireless.sta.ssid=\u0026#39;所中继连接的源WIFI-名称\u0026#39; 网络信息 uci show network：\nnetwork.loopback=interface network.loopback.ifname=\u0026#39;lo\u0026#39; network.loopback.proto=\u0026#39;static\u0026#39; network.loopback.ipaddr=\u0026#39;127.0.0.1\u0026#39; network.loopback.netmask=\u0026#39;255.0.0.0\u0026#39; network.globals=globals network.globals.ula_prefix=\u0026#39;fd15:39fa:4166::/48\u0026#39; network.lan=interface network.lan.ifname=\u0026#39;eth0.1\u0026#39; network.lan.force_link=\u0026#39;1\u0026#39; network.lan.macaddr=\u0026#39;b8:d8:12:67:01:71\u0026#39; network.lan.type=\u0026#39;bridge\u0026#39; network.lan.proto=\u0026#39;static\u0026#39; network.lan.ipaddr=\u0026#39;192.168.61.1\u0026#39; network.lan.netmask=\u0026#39;255.255.255.0\u0026#39; network.lan.ip6assign=\u0026#39;60\u0026#39; network.wan=interface network.wan.ifname=\u0026#39;eth0.2\u0026#39; network.wan.force_link=\u0026#39;1\u0026#39; network.wan.macaddr=\u0026#39;b8:d8:12:67:01:72\u0026#39; network.wan.proto=\u0026#39;dhcp\u0026#39; network.wan6=interface network.wan6.ifname=\u0026#39;eth0.2\u0026#39; network.wan6.proto=\u0026#39;dhcpv6\u0026#39; network.@switch[0]=switch network.@switch[0].name=\u0026#39;switch0\u0026#39; network.@switch[0].reset=\u0026#39;1\u0026#39; network.@switch[0].enable_vlan=\u0026#39;1\u0026#39; network.@switch_vlan[0]=switch_vlan network.@switch_vlan[0].device=\u0026#39;switch0\u0026#39; network.@switch_vlan[0].vlan=\u0026#39;1\u0026#39; network.@switch_vlan[0].ports=\u0026#39;1 2 3 4 6t\u0026#39; network.@switch_vlan[1]=switch_vlan network.@switch_vlan[1].device=\u0026#39;switch0\u0026#39; network.@switch_vlan[1].vlan=\u0026#39;2\u0026#39; network.@switch_vlan[1].ports=\u0026#39;0 6t\u0026#39; 注意此处没有lan_dev桥接网络，并且有固定的mac地址，所以能从以太网分配到IP（待确认，openwrt 18.06.1 默为桥接以太网https://unix.stackexchange.com/questions/493378/no-ethernet-ip-address-in-my-vocore2) 。\n配置好后的无线网络信息截图如下： 如果喜欢通过图形界面进行设置，请参考vonger的博客。不过个人偏好命令行配置（uci），更简单可靠。\n相关问题 # 供电电压过低时STA模式不能正常工作\n此时一般会提示[ 826.460057] MlmeEnqueueForRecv(): un-recongnized mgmt-\u0026gt;subtype=4, STA-xx:xx:xx:xx:xx:xx的日志错误信息。\n参考github上的这个Issue\npppoe(ASDL拨号上网) # 添加vlan端口 设置wan接口连接方式为pppoe和以上vlan端口 代理与Web过滤（Shadowsocks + Privoxy） # Shadowsocks\n考虑到go此时对mipsel架构的支持还有限, 而且openWRT版本的shadowsocks-libev具有体积小、轻量级、功能支持丰富的特点，就采用了shadowsocks-libev来作为Shadowsocks的客户端。\n这里使用了OpenWrt-dist提供的源进行安装。可以通过命令从远程下载直接安装，也可以下载指定ipk安装包后进行安装。\nopkg install shadowsocks-libev-ss-local luci-app-shadowsocks-libev v2ray需要openwrt支持SSL， 我们可以启用luci的SSL顺便解决该问题\nopkg install luci-ssl-openssl ca-bundle luci-ssl-nginx 注意这里我们使用luci-ssl-nginx替换原有的httpd，uhttpd目前会有性能问题导致https页面加载非常慢。\nPrivoxy\n当前所使用的OpenWRT版本已经支持从官方源中下载安装privoxy, 也可以去http://downloads.openwrt.org/找到对应的privoxy安装包手动下载安装。\n目前我所使用的privoxy版本信息为：Privoxy version 3.0.26 (https://www.privoxy.org/)，但是我在使用它的时候不太确定是否一个bug, 通过uci所配置的list项信息（如actionsfile和filterfile）无法生效，故修改了/etc/init.d/privoxy启动脚本并使用树莓派上privoxy的默认配置文件/etc/privoxy/config作为配置，回退到旧的配置方式。\n重要配置示例：\n# filename: pac.action # please add pac.action actionsfile into /etc/privoxy/config {{alias}} # http = +forward-override{forward 127.0.0.1:8080} direct = +forward-override{forward .} socks5 = +forward-override{forward-socks5 127.0.0.1:1080 .} default = direct # Default proxy {default} / {direct} .edu.cn .lan # Shadowsocks {socks5} .abc.xyz .google.com.hk uci add_list privoxy.privoxy.actionsfile=pac.action BBR # opkg install kmod-tcp-bbr 网络包分析 # 安装以下软件包，以便进行网络数据包分析。vocore2性能有限，只适合抓包和处理少量的数据包。\nlibpcap reaver aircrack-ng airmon-ng tcpdump 显示多个SSID # 修改/etc/wireless/mt7628/mt7628.dat (实际上为文本文件)：\n# BSSID数量设为4 ra0, ra1, ra2, ra3 BssidNum=4 SSID1=VoCore2 SSID2=VoCore2-GUEST SSID3=VoCore2-HOST SSID4=VoCore2-NAS 参考： http://vonger.cn/?p=14496\n启用网卡嗅探(Sniffer)模式 # # Supposed libpcap.ipk and tcpdump.ipk have been installed. # MonitorMode=2 is MONITOR_MODE_FULL, =1 is MONITOR_MODE_REGULAR_RX, =0 is OFF. ifconfig mon0 up iwpriv ra0 set MonitorMode=2 # capturing tcpdump -i mon0 -w /tmp/store.cap -vv Packet capturing of raw 802.11 frames (use tcpdump alternative to airodump-ng)\nset channel to the same as AP (needed, otherwise you\u0026rsquo;re not able to capture the handshake packets, check https://www.aircrack-ng.org/doku.php?id=cracking_wpa#aircrack-ng_says_0_handshakes) 以下方式在vocore中暂时不能使用\n# check current channel of the interface iwlist mon0 channel # change channel iwconfig mon0 channel \u0026lt;CHANNEL_NUM\u0026gt; 改变无线网卡的CHANNEL\nuci set wireless.@wifi-device[0].channel=6 Use cap2hccapx to filter packets cap2hccapx.bin /tmp/store.cap tmp.hccap 查看AP已经连接的CLIENT信息 airodump-ng 同时可以用来过滤握手包，可以在tcpdump抓包的同时使用该工具查看数据包文件\nairodump-ng -c \u0026lt;TARGET-CH\u0026gt; --bssid \u0026lt;SSID\u0026gt; -r /tmp/store.cap 发送DEAUTH包强制断开已连接WIFI的客户端 aireplay-ng -0 2 -a \u0026lt;SSID\u0026gt; -c \u0026lt;CLIENT-MAC\u0026gt; mon0 参考\nhttp://vonger.cn/?p=14501 https://wiki.openwrt.org/zh-cn/doc/uci/wireless 远程下载 （aria2) # 采用默认配置\naria2 luci-app-aria2 在界面上配置启用和下载目录，开放路由远程监听端口，可通过luci界面配置进行管理下载\n客户端 # web: https://github.com/ziahamza/webui-aria2 android: Aria2App https://play.google.com/store/apps/details?id=com.gianlu.aria2app\u0026hl=zh 参考https://aria2.github.io/\nUSB 2.0存储挂载 # 可通过Web界面luci进行管理，手动挂载存储设备 (系统-\u0026gt; 挂载点) 参考 https://openwrt.org/docs/guide-user/storage/fstab\nkmod-usb2 block-mount kmod-usb-storage kmod-usb-storage-uas opkg install kmod-fs-exfat kmod-fs-ext4 kmod-fs-ntfs kmod-fs-vfat 手动mount存储介质到/mnt/sda1目录\n# 假设移动存储设备为/dev/sda1 mkdir /mnt/sda1 mount /dev/sda1 /mnt/sda1 参考openWRT官方文档usb.essentials\nNAS服务 # 这里列出了许多NAS服务https://openwrt.org/docs/guide-user/services/nas/start 。\n我主要考虑了两种：nfs和samba。推荐使用nfs, 性能更好一点\n安装可以参考官方文档https://openwrt.org/docs/guide-user/services/nas/cifs.server\nPS: http服务器可以使用uhttpd服务，默认根目录在/www, 可以新建一个shared文件夹，把文件丢过去就好了（只推荐存储小的配置文件); 参考https://openwrt.org/docs/guide-user/services/webserver/http.uhttpd\n声音播放与流媒体功能（DLNA) # 采用默认配置\nminidlna luci-app-minidlna 更改dlna根目录\nuci set minidlna.config.media_dir=\u0026#39;/mnt/usb\u0026#39; uci set minidlna.config.user=\u0026#39;root\u0026#39; 配置示例\nminidlna.config=minidlna minidlna.config.enabled=\u0026#39;1\u0026#39; minidlna.config.port=\u0026#39;8200\u0026#39; minidlna.config.interface=\u0026#39;br-lan\u0026#39; minidlna.config.friendly_name=\u0026#39;OpenWrt DLNA Server\u0026#39; minidlna.config.db_dir=\u0026#39;/var/run/minidlna\u0026#39; minidlna.config.log_dir=\u0026#39;/var/log\u0026#39; minidlna.config.inotify=\u0026#39;1\u0026#39; minidlna.config.enable_tivo=\u0026#39;0\u0026#39; minidlna.config.wide_links=\u0026#39;0\u0026#39; minidlna.config.strict_dlna=\u0026#39;0\u0026#39; minidlna.config.notify_interval=\u0026#39;900\u0026#39; minidlna.config.serial=\u0026#39;12345678\u0026#39; minidlna.config.model_number=\u0026#39;1\u0026#39; minidlna.config.root_container=\u0026#39;.\u0026#39; minidlna.config.album_art_names=\u0026#39;Cover.jpg/cover.jpg/AlbumArtSmall.jpg/albumartsmall.jpg/AlbumArt.jpg/albumart.jpg/Album.jpg/album.jpg/Folder.jpg/folder.jpg/Thumb.jpg/thumb.jpg\u0026#39; minidlna.config.media_dir=\u0026#39;/mnt/sda1\u0026#39; 参考https://openwrt.org/docs/guide-user/services/media_server/minidlna\nGuest WIFI和wifidog # 参考openwrt此官方文档创建guest开放网络 安装nodogsplash,并设置用户名密码登录 https://nodogsplash.readthedocs.io/en/latest/binauth.html 设定需要portal登录的interface为br-guest 使用splash.html认证的方式密码是明文，建议偶尔使用，长期使用可改用FAS登录。 Web管理界面luci中文支持 # 安装中文语言包 和 material界面\nopkg install luci-i18n-base-zh-cn luci-theme-material 然后在luci界面上选择中文作为默认语言。\n变成“假硬币”怎么办？ # 一般情况下，如果设定了错误的配置导致vocore无法正常工作，可以尝试修复配置完成。这里只给出个人的方案，官网有更全面更安全的方式。\n如果修复不了配置，直接恢复到默认设置：\nfirstboot \u0026amp;\u0026amp; reboot 如果是固件出现了问题，可尝试通过刷入新的固件来解决\nsysupgrade -v \u0026lt;VOCORE-FIRMWARE.BIN\u0026gt; 如果无法通过网络连接vocore，那么只用尝试通过串口连接了。\n使用串口连接vocore # 设定好参数后可以通过USB串口连接到vocore2 UART speed: 115200bps; 8bits; no even; 1 stop bit\nWindows下putty连接COM端口 (驱动usb2ttl) Ubuntu中使用minicom连接 使用串口刷入固件（仅在sysupgrade方式不可用时推荐) # 安装ckermit sudo apt-get install ckermit # 旧版本ckermit在Ubuntu 20.04中已经废弃, The Kermit Project at Columbia University is cancelled effective 1 July 2011 # 从新网站下载源码编译 http://www.kermitproject.org/ck90.html make linux sudo make install 配置 /etc/kermit/kermrc 或者/root/.mykermrc`\n; 添加如下内容 set line /dev/ttyACM0 set speed 115200 set carrier-watch off set handshake none set flow-control none robust set file type bin set file name lit set rec pack 1000 set send pack 1000 set window 5 使用minicom连接vocore2并选择0: Load system code then write to Flash via SERIAL. # config Minicom sudo minicom -s # connect sudo minicom 接上电源启动vocore并快速按0，进入刷机模式\n使用minicom传输固件 vocore2进入待刷机模式后，按下快捷键Ctrl+A+Z, 打开minicom菜单选择send files,并使用kermit协议，然后输入文件名回车开始发送文件，完成刷机。 Compile OpenWRT for VoCore2 # Install packages to compile OpenWRT sudo apt-get install gcc g++ binutils patch bzip2 flex bison make autoconf gettext texinfo unzip sharutils subversion libncurses5-dev ncurses-term zlib1g-dev libssl-dev python Follow link https://github.com/Vonger/vocore2 指定内核版本 include/kernel-version.mk\nPS： 如果想购买一个玩一下，不必在官网上买，国内某宝上有卖，而且貌似是官方的，因为它来自中国。\nOpenWRT 18.06 # 当前vocore2的官方固件基于openwrt 15.05, 该版本openwrt支持的软件包比较少，openwrt 18.06对vocore已有较好的支持。\n推荐：刷入vonger提供的vocore2固件 http://vonger.cn/misc/vocore2/20180419.bin\n注意默认配置下openwrt未启用AP模式,使用以下命令更改(使用vonger固件不需要执行该命令)\nuci set wireless.@wifi-device[0].disabled=0; uci commit wireless; wifi OpenWRT相关DIY # 小米路由器3g (256MB内存版本, 2代貌似涨价了而且配置缩水了)\n刷机等相关文档参考这个链接 https://forum.openwrt.org/t/xiaomi-wifi-router-3g/5377\n提示：mt7621 v2ray版本选择mipsle_sf\nDNS配置 # 我们配置dns避免DNS污染和劫持\n设置上游DNS # Configure DNS provider uci -q delete network.wan.dns uci add_list network.wan.dns=\u0026#34;8.8.8.8\u0026#34; uci add_list network.wan.dns=\u0026#34;8.8.4.4\u0026#34; # Configure DNS6 provider uci -q delete network.wan6.dns uci add_list network.wan6.dns=\u0026#34;2001:4860:4860::8888\u0026#34; uci add_list network.wan6.dns=\u0026#34;2001:4860:4860::8844\u0026#34; # Disable peer DNS uci set network.wan.peerdns=\u0026#34;0\u0026#34; uci set network.wan6.peerdns=\u0026#34;0\u0026#34; # Save and apply uci commit network /etc/init.d/network restart 参考 https://openwrt.org/docs/guide-user/base-system/dhcp_configuration\ndns over https 参考 https://openwrt.org/docs/guide-user/services/dns/doh_dnsmasq_https-dns-proxy\n源镜像 # https://mirrors.tuna.tsinghua.edu.cn/openwrt\nsed -i \u0026#39;s/http:\\/\\/downloads.openwrt.org/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/openwrt/g\u0026#39; distfeeds.conf 推荐使用openwrt官网固件。 目前固件较稳定19.07，使用稳定发布版本可以找到完整的依赖包。保持与默认界面与设置统一。\nwan 口和 lan口互换 # 默认以太网口为lan口，可以通过以太网共享vocore网络给其他设备。\n切换为wan口，只需要将wan设备的物理接口换成eth0.1, 将lan设备的物理接口换成eth0.2\n此链接仅供参考http://vonger.cn/?p=8127\nVLAN # https://x-nagi.com/2019/openwrt-and-switch.html\nhttps://zhuanlan.zhihu.com/p/35616289\n主机映射\n4G LTE # dial.sh script #!/bin/bash if [ ! \u0026#34;$(lsusb -d \u0026#39;161c:f010\u0026#39;)\u0026#34; ]; then printf \u0026#34;usb not plugged\\n\u0026#34; ; fi # switch from mass storage to modem devices #usb_modeswitch -v 161c -p f010 -W -M 55534243123456780000000000000606f50402527000000000000000000000 usbmode -s -v -c usb-mode.json modprobe qmi_wwan echo \u0026#34;161c f101\u0026#34; \u0026gt; /sys/bus/usb/drivers/qmi_wwan/new_id sleep 2 echo 1-1:1.0 \u0026gt; /sys/bus/usb/drivers/qmi_wwan/unbind echo 1-1:1.1 \u0026gt; /sys/bus/usb/drivers/qmi_wwan/unbind sleep 1 echo 1-1:1.1 \u0026gt; /sys/bus/usb/drivers/qmi_wwan/bind sleep 1 modprobe option echo \u0026#39;161c f101\u0026#39; \u0026gt; /sys/bus/usb-serial/drivers/option1/new_id ifup wan # ip route add default dev 3g-wan metric 100 network config set metric to 100, so network traffic goes through this interface by default.\nconfig interface \u0026#39;wan\u0026#39; option device \u0026#39;/dev/ttyUSB0\u0026#39; option apn \u0026#39;3gnet\u0026#39; option proto \u0026#39;3g\u0026#39; option service \u0026#39;umts\u0026#39; option ipv6 \u0026#39;auto\u0026#39; option dialnumber \u0026#39;*99#\u0026#39; option ifname \u0026#39;ppp0\u0026#39; option metric \u0026#39;100\u0026#39; usb-mode.json { \u0026#34;messages\u0026#34; : [ \u0026#34;55534243123456780000000000000606f50402527000000000000000000000\u0026#34;, ], \u0026#34;devices\u0026#34; : { \u0026#34;161c:f010\u0026#34;: { \u0026#34;*\u0026#34;: { \u0026#34;t_vendor\u0026#34;: 5660, \u0026#34;t_product\u0026#34;: [ 61697 ], \u0026#34;msg\u0026#34;: [ 0 ], \u0026#34;response\u0026#34;: true } }, } } 参考链接 # https://help.ubuntu.com/community/Minicom http://vocore.io/v2.html https://openwrt.org/docs/guide-user/network/wifi/relay_configuration http://downloads.openwrt.org/snapshots/targets/ramips/mt76x8/packages/ https://wiki.openwrt.org/zh-cn/doc/techref/opkg https://oldwiki.archive.openwrt.org/doc/uci/wireless http://vonger.cn/misc/vocore2/ https://openwrt.org/docs/guide-user/luci/start "},{"id":26,"href":"/notes/iot/rpi/setup-my-raspberrypi/","title":"My notes on Raspberry Pi","section":"Notes","content":" Headless setup (no external monitor or keyboard) # Updated: according to the Raspibian Documentation, use Raspberry Pi Imagger is strongly recommended\nNetworking # Auto connect to wifi create an wpa_supplicant.conf file in boot partition\ncountry=us update_config=1 ctrl_interface=/var/run/wpa_supplicant network={ scan_ssid=1 ssid=\u0026#34;Your-SSID\u0026#34; psk=\u0026#34;replace-with-your-password\u0026#34; priority=100 } Connect to WIFI with CLI Refer to https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md\nEnable SSH # Simply create an empty ssh file in the root directory of boot partition.\nRefer to https://www.raspberrypi.org/documentation/remote-access/ssh/\nGet IP of your pi # With Computer # sudo nmap -sP 192.168.21.* # results MAC Address: B8:27:EB:40:A9:D7 (Raspberry Pi Foundation) Nmap scan report for 192.168.31.158 With Android Phone # Install connectBot or other terminal app Share the network of your android device with usb network; Enter local mode, use ip neighbor command to get the ip address of your raspberrypi Now you can ssh to your raspberry pi with this ip.\nCompiling kernel manually # Refer to https://www.raspberrypi.org/documentation/linux/kernel/building.md\nNote that you may need to change /dev/sdbX with /dev/mmcblk0pN\nmmcblk0 179:0 0 29G 0 disk ├─mmcblk0p1 179:1 0 43.9M 0 part └─mmcblk0p2 179:2 0 28.9G 0 part Prevent kernel package from being automatically installed\nsudo apt-mark hold raspberrypi-kernel Android # Refer to https://konstakang.com/devices/rpi3/LineageOS15.1/\nJust for fun, not recommend to use it as a real android device.\nChange Raspbian mirror source # Refer to https://mirror.tuna.tsinghua.edu.cn/help/raspbian/\nReference # https://www.waveshare.com/wiki/RPi_IR-CUT_Camera "},{"id":27,"href":"/notes/dev/git-quick-guide/","title":"Git快速手册","section":"Notes","content":"WIP\n快速开始 # 设置个人信息 git config --global user.name \u0026lt;YOUR-NAME\u0026gt; git config --global user.email \u0026lt;YOUR-EMAIL\u0026gt; # 查看个人配置 git config --list 将默认主仓库设置为main BLM运动 git config --global init.defaultbranch main 初始化仓库 mkdir /path/to/your/project cd /path/to/your/project git init # initialize an empty git repo git remote add origin git@repo-url.git Create your first file and push it to the remote repo # echo \u0026#34;qtopie.rw\u0026#34; \u0026gt;\u0026gt; contributors.txt git add contributors.txt git commit -m \u0026#39;Initial commit with contributors\u0026#39; git push -u origin master 总结下常用操作\ngit init git add . git commit -m \u0026#34;first commit\u0026#34; git remote add origin remote \u0026lt;repo-url\u0026gt; git branch --set-upstream-to origin/main main git remote -v git push More # change a commit message: git commit --amend Creating Release # Tag # list Tag git tag create new tag git tag v0.2 push new tag git push origin v0.2 delete a tag git tag -d v0.21 Pull Request (PR) # Steps\nFork the original repo\nClone your forked repo and create a feature branch with the head refs from original repo (named upstream)\ngit fetch upstream # Name of feature branch is BRANCH-FOO git checkout -b upstream/BRANCH-FOO Supposed you have made modifications locally, and added codes and committed the changes, now push it to your forked repo and create a new branch if it does not exist.\ngit push -u origin BRANCH-FOO Then creating a merge request to original repo, and ask someone to review the codes, either accept or close the merge request.\nNote that you can use git stash if you want to switch branches without bringing changes into another branch.\n代理设置 # socks5 git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; # http git config --global http.proxy \u0026#39;http://127.0.0.1:3128\u0026#39; git config --global https.proxy \u0026#39;http://127.0.0.1:3128\u0026#39; 参考 # https://www.atlassian.com/git/tutorials/making-a-pull-request https://www.atlassian.com/git/tutorials/comparing-workflows GitFlow "},{"id":28,"href":"/notes/cloud-native/cicd/dockerfile/","title":"Dockerfile","section":"Notes","content":" Introduction # Docker, an opensource container management tool based on LXC(Linux container).\n"},{"id":29,"href":"/notes/web/regex/","title":"Regular Expression","section":"Notes","content":" username:\n^[a-z0-9_-]{3,16}$ // any character of a-z, 0-9, underscore and \u0026lsquo;-\u0026rsquo;\npassword:\nsimilar to username\nemail:\n^([a-z0-9_\\.-]+)@([a-z0-9_\\.-]+)\\.([a-z\\.]{2,6})$\nurl:\n^(https?:\\/\\/)?(\\da-z\\.-]+)\\.([a-z\\.]{2,6})([/\\w\\.-]*)*\\/?$\nnot\n[^]\nabc…\tLetters 123…\tDigits \\d\tAny Digit \\D\tAny Non-digit character .\tAny Character \\.\tPeriod [abc]\tOnly a, b, or c [^abc]\tNot a, b, nor c [a-z]\tCharacters a to z [0-9]\tNumbers 0 to 9 \\w\tAny Alphanumeric character \\W\tAny Non-alphanumeric character {m}\tm Repetitions {m,n}\tm to n Repetitions -\tZero or more repetitions +\tOne or more repetitions ?\tOptional character \\s\tAny Whitespace \\S\tAny Non-whitespace character ^…$\tStarts and ends (…)\tCapture Group (a(bc))\tCapture Sub-group (.*)\tCapture all (abc|def)\tMatches abc or def To help you better understand the regular expressions, Visualized with Regexper\nCode # import java.util.regex.Matcher; import java.util.regex.Pattern; /** * By this example you should know how to find a digit string fro the given alphanumeric string **/ public class RegexMatches{ public static void main(String args[]){ // String to be scanned to find the pattern. String line =\u0026#34;This order was places for QT3000! OK?\u0026#34;; /** * . matches any single character except newline * re* mathches 1 ore more occurrences of preceding expression * re+ matches 1 ore more of the previous thing * \\d matches digits */ String pattern =\u0026#34;(.*)(\\\\d+)(.*)\u0026#34;; // Create a Pattern object Pattern r =Pattern.compile(pattern); // Now create matcher object. Matcher m = r.matcher(line); if(m.find()){ System.out.println(\u0026#34;Found value: \u0026#34;+ m.group(0)); // () means a group System.out.println(\u0026#34;Found value: \u0026#34;+ m.group(1)); System.out.println(\u0026#34;Found value: \u0026#34;+ m.group(2)); }else{ System.out.println(\u0026#34;NO MATCH\u0026#34;); } }\t} "},{"id":30,"href":"/notes/linux/systemd-service-unit-file/","title":"Ubuntu init process","section":"Notes","content":" History # sysVinit upstart systemd ubuntu: sysVinit \u0026ndash;\u0026gt; upstart(6.10+) \u0026ndash;\u0026gt; systemd (15.04+)\nFeatures of Upstart # Event Based\nStart System faster (compare with previous method). Dynamically start service when discovering new device Dynamically stop service when device is removed Systemd # Systemd is a collection of system management daemons, utilities and libraries which serves as a replacement of System V init daemon. Systemd functions as central management and configuration platform for UNIX like system.\nsystemctl # Systemctl is a systemd utility which is responsible for Controlling the systemd system and service manager.\nInit script vs Service file # You may use service SCRIPT start|stop|statu.. manage jobs, but it\u0026rsquo;s different between using Init script and upstart or systemd service file. see man service.\nSystem V init script # located in /etc/init.d/SCRIPT\nExample: (from shadowsocks-go project) #!/bin/bash # Start/stop shadowsocks. # ### BEGIN INIT INFO # Provides: shadowsocks # Required-Start: # Required-Stop: # Should-Start: # Should-Stop: # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: shadowsocks is a lightweight tunneling proxy # Description: Modified from Linode\u0026#39;s nginx fastcgi startup script ### END INIT INFO # Note: this script requires sudo in order to run shadowsocks as the specified # user. BIN=/usr/bin/shadowsocks-local CONFIG_FILE=/etc/shadowsocks/config.json LOG_FILE=/var/log/shadowsocks USER=nobody GROUP=nobody PID_DIR=/var/run PID_FILE=$PID_DIR/shadowsocks.pid RET_VAL=0 [ -x $BIN ] || exit 0 check_running() { if [[ -r $PID_FILE ]]; then read PID \u0026lt;$PID_FILE if [[ -d \u0026#34;/proc/$PID\u0026#34; ]]; then return 0 else rm -f $PID_FILE return 1 fi else return 2 fi } do_status() { check_running case $? in 0) echo \u0026#34;shadowsocks running with PID $PID\u0026#34; ;; 1) echo \u0026#34;shadowsocks not running, remove PID file $PID_FILE\u0026#34; ;; 2) echo \u0026#34;Could not find PID file $PID_FILE, shadowsocks does not appear to be running\u0026#34; ;; esac return 0 } do_start() { if [[ ! -d $PID_DIR ]]; then echo \u0026#34;creating PID dir\u0026#34; mkdir $PID_DIR || echo \u0026#34;failed creating PID directory $PID_DIR\u0026#34;; exit 1 chown $USER:$GROUP $PID_DIR || echo \u0026#34;failed creating PID directory $PID_DIR\u0026#34;; exit 1 chmod 0770 $PID_DIR fi if check_running; then echo \u0026#34;shadowsocks already running with PID $PID\u0026#34; return 0 fi if [[ ! -r $CONFIG_FILE ]]; then echo \u0026#34;config file $CONFIG_FILE not found\u0026#34; return 1 fi echo \u0026#34;starting shadowsocks\u0026#34; # sudo will set the group to the primary group of $USER sudo -u $USER $BIN -c $CONFIG_FILE \u0026gt;\u0026gt;$LOG_FILE \u0026amp; PID=$! echo $PID \u0026gt; $PID_FILE sleep 0.3 if ! check_running; then echo \u0026#34;start failed\u0026#34; return 1 fi echo \u0026#34;shadowsocks running with PID $PID\u0026#34; return 0 } do_stop() { if check_running; then echo \u0026#34;stopping shadowsocks with PID $PID\u0026#34; kill $PID rm -f $PID_FILE else echo \u0026#34;Could not find PID file $PID_FILE\u0026#34; fi } do_restart() { do_stop do_start } case \u0026#34;$1\u0026#34; in start|stop|restart|status) do_$1 ;; *) echo \u0026#34;Usage: shadowsocks {start|stop|restart|status}\u0026#34; RET_VAL=1 ;; esac exit $RET_VAL You can use update-rc.d command to update the system service definitions.\nSystemd Unit file # Example (/etc/systemd/system/shadowsocks.service)\nPrepare the executable file with the custom service. Create a unit file in the /etc/systemd/system/ directory and make sure it has correct file permissions. Execute as root: touch /etc/systemd/system/shadowsocks.service chmod 644 /etc/systemd/system/shadowsocks.service Edit shadowsocks.service file Shadowsocks-local [Unit] Description=Shadowsocks local daemon After=network.target [Service] ExecStart=/usr/bin/shadowsocks-local -c /etc/shadowsocks/config.json PIDFile=/var/run/shadowsocks.pid KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=default.target Shadowsocks-server [Unit] Description=Go Shadowsocks server daemon Wants=network-online.target After=network.target network-online.target multi-user.target [Service] ExecStart=/usr/bin/shadowsocks-server -u -c /etc/shadowsocks/config.json ExecReload=/bin/kill -HUP $MAINPID PIDFile=/var/run/shadowsocks.pid KillMode=process Restart=on-failure TimeoutStopSec=30 [Install] WantedBy=multi-user.target Alias=ss-server.service Proxy setting Environment=\u0026#34;HTTP_PROXY=http://127.0.0.1:8118\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://127.0.0.1:8118\u0026#34; Environment=\u0026#34;NO_PROXY=pi.lan,127.0.0.1\u0026#34; Check Environment setting [example home-assistant-@pi.servie]:\nsudo systemctl show home-assistant@pi.service --property Environment # Output: # Environment=HTTP_PROXY=http://127.0.0.1:8118 HTTPS_PROXY=http://127.0.0.1:8118 NO_PROXY=pi.lan,127.0.0.1 Notify systemd that a new shadowsocks.service file exists by executing the following command as root systemctl daemon-reload # start shadowsocks service systemctl start shadowsocks.service You can check its status now by service shadowsocks status To add it to startup, using systemctl enable shadowsocks\nCheck details of running status service shadowsocks status -l # or journalctl -xe upstart job is configured in /etc/init/\nShell script with systemd unit A sample with java web application.\ndummy service\n[Unit] Description=Dummy daemon Wants=network-online.target After=network.target network-online.target multi-user.target [Service] ExecStart=/usr/bin/dummy ExecReload=/bin/kill -HUP $MAINPID PIDFile=/var/run/dummy.pid KillMode=process Restart=on-failure TimeoutStopSec=30 [Install] WantedBy=multi-user.target dummy script to start\n#/bin/bash JAVA_HOME=\u0026#34;${JAVA_HOME:-/usr/lib/jvm/default}\u0026#34; JAVA_OPTS=\u0026#34;-XX:+UnlockExperimentalVMOptions -XX:-UseJVMCICompiler\u0026#34; JAVA_OPTS=\u0026#34;${JAVA_OPTS} -Xms1024m -Xmx2048m -XX:PermSize=32m\u0026#34; DUMMY_PROGRAM=\u0026#34;/opt/dummy/dummy.jar\u0026#34; START_CMD=\u0026#34;${JAVA_HOME}/bin/java ${JAVA_OPTS} -jar ${DUMMY_PROGRAM}\u0026#34; LOG_FILE=/var/log/dummy init() { touch ${LOG_FILE} } check_running() { logger -i -t \u0026#34;It\u0026#39;s running\u0026#34; -f ${LOG_FILE} } check_deps() { echo \u0026#34;Ok\u0026#34; } start() { eval ${START_CMD} echo \u0026#34;It\u0026#39;s started\u0026#34;\t} main() { init check_running check_deps start \u0026amp; } main \u0026#34;$@\u0026#34; Reference # https://wiki.ubuntu.com/systemd https://wiki.debian.org/Debate/initsystem/sysvinit http://0pointer.de/public/systemd-man/ https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/System_Administrators_Guide/sect-Managing_Services_with_systemd-Unit_Files.html https://home-assistant.io/docs/autostart/systemd/ "},{"id":31,"href":"/notes/linux/hostapd-wifi/","title":"Wifi with hostapd","section":"Notes","content":" Hostapd # hostapd is a user space daemon for access point and authentication server.\nPlease follow the guide of Official documentation\nInstallation and configuration # Tested on raspbian with raspberry pi 3\nInstall hostapd and configure it # sudo apt-get install hostapd -y --force-yes, also sudo apt-get install haveged\nEdit hostapd.conf: /etc/hostapd/hostapd.conf\ninterface=wlan0 ssid=RPi wpa_passphrase=raspberrypi auth_algs=1 wpa=2 wpa_key_mgmt=WPA-PSK rsn_pairwise=CCMP channel=10 hw_mode=g There should not be any whitespace at the end of each line\nthen modify file /etc/default/hostapd to let the configuration work automatically.\nYou may turn of the wifi and test it with : hostapd -d /etc/hostapd/hostapd.conf you will see the ssid RPi in wireless network list, but you cannot connect to it yet.\nTips: if you have trouble with testing, try ifdown wlan0 (in raspbian) to bring down wifi device ( rfkill with network-manager)\ndhcp ip address # setting static ip address sudo vim /etc/network/interfaces supposed the interface name is wlan0:\nallow-hotplug wlan0 iface wlan0 inet static address 10.0.0.1 netmask 255.255.255.0 network 10.0.0.0 broadcast 10.0.0.255 also make dhcpcd not manage wlan0 interface\necho \u0026#34;denyinterfaces wlan0\u0026#34; \u0026gt;\u0026gt; /etc/dhcpcd.conf dnsmasq sudo apt-get install dnsmasq configuration\ninterface=wlan0 dhcp-range=10.0.0.100,10.0.0.150,255.255.255.0,12h # dns domain-needed listen-address=127.0.0.1,10.0.0.1 listen-address=::1 #resolv-file=/etc/resolv.dnsmasq.conf #local=/pi.lan/ #domain=pi.lan #expand-hosts # address=/#/10.0.0.1 #address=/pi.lan/10.0.0.1 dhcp-option=option:router,10.0.0.1 # raspberry pi 2 #dhcp-host=raspberrypi2,10.0.0.102,36h cache-size=600 # default is 150 log-async=20 you may test it with dnsmasq --test\nPort forwarding and NAT traffic # Find and uncomment these lines in file /etc/sysctl.conf:\nnet.ipv4.ip_forward=1 net.ipv6.conf.all.forwarding=1 add following lines before line exit 0 to have NAT traffic forwarded:\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE iptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPT iptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT Or to make the rules to be applied every time on boot, run: sudo sh -c \u0026#34;iptables-save \u0026gt; /etc/iptables.ipv4.nat\u0026#34; ``` to save the rules to the file `/etc/iptables.ipv4.nat` Make it restore on boot by add ``` iptables-restore \u0026lt; /etc/iptables.ipv4.nat ``` in /etc/rc.local above the `exit 0` line. ## Now you may reboot the os to make it work well and have a try. ## Reference: 1. (http://www.ibm.com/developerworks/cn/linux/l-wifiencrypthostapd/) 2. (https://wireless.wiki.kernel.org/en/users/documentation/hostapd) 3. (https://help.ubuntu.com/community/NetworkConfigurationCommandLine/Automatic) 4. https://help.ubuntu.com/community/WifiDocs/WirelessAccessPoint Other: [scripts](https://github.com/oblique/create_ap) "},{"id":32,"href":"/posts/hugo/getting-started-with-hugo/","title":"使用Hugo生成静态站点","section":"Posts","content":"本文主要分享如何使用Hugo生成静态站点，并部署到firebase (Hosting服务）上。\nupdated: 2021/9/29\n静态站点 # 静态站点，相比于动态站点（一般指需要请求后端动态生成网站内容）来说，网站内容已提前渲染好，对搜索引擎更加友好。而且网站内容一般可以直接生成静态的html/css页面, 减少浏览器js渲染，网络传输时也可以充分利用缓存, 这样网页加载也比较快， 使用户体验更好。\n更进一步地，Google和Twitter合作开发了AMP(Accelerated Mobile Pages)技术, 通过限定HTML标签和CSS，以及CDN缓存，提升移动设备(相比于PC端：弱网、低性能）对网站的访问速度。\n本站点就是采用了AMP技术构建, 使用静态站点生成工具根据模板，将markdown文件渲染输出为静态AMP页面。\n生成工具 # 静态站点生成工具有很多，我主要用过的有以下两个。（目前又换回了Hugo)\nHugo Scully PS, Hugo刚发布不久我就开始使用了，当时对这个新工具很喜欢，它是一个单独的二进制文件, 且渲染很快，模板丰富。但后面想定制一些功能（那时Hugo的文档比较少，仅官网使用文档， 且功能也没现在这么丰富), 但go的语法还是比较复杂的，也没太多时间看源码。因此当Scully出现的时候，我就立即使用了它（因为本人还是一个Angular粉），相比于Hugo，Scully几乎等同于你可以通过编写Angular应用定制你的网站, 因此十分灵活（主要的缺点是主题和应用代码分开进程渲染，调试略麻烦）。但后面发现，我本身写博客主题的时间可能比我写博客还花的多：》，也是该冷静下想想我的初衷是什么了。其实就是为了记录一些知识并分享，因此AMP才是我的需要。所以我决定我的博客主题的核心是简洁并对阅读友好, 而不是增添许多看其来很有趣的功能。\n博客主题 # 这里列出我用过的博客主题\nHugo\nRobust amp-blog-theme Scully\nmdblog-theme 以下内容主要介绍Hugo使用\n安装和创建站点 # 目标 # 在本地电脑安装hugo, 在github上创建私有仓库posts，存放markdown源码及图片等文件； 在github创建私有仓库qtopie.web.app（作为集成仓库）, 对应于站点名称，存放站点配置文件。 创建firebase hosting项目，将站点qtopie.web.app发布到firebase. 仓库创建过程省略\nHugo安装 # 以在Ubuntu 20.04上为例\nsudo snap install hugo 本地生成站点 # 初始化git各模块\n// git clone ... ; cd \u0026lt;repo\u0026gt; hugo new site . git submodule add https://github.com/qtopierw/amp-blog-theme.git themes/amp-blog-theme git submodule add git@github.com:\u0026lt;username\u0026gt;/posts.git content/posts 创建.gitignore文件, 并加入public目录\n现在可以使用hugo命令生成站点了（将输出到public目录），或使用hugo server命令进入开发模式\n将应用发布到firebase # firebase工具安装 # firbase是一个nodejs应用工具包，需要使用npm或者yarn安装\nsudo yarn global add firebase-tools 发布 # 登录firebase账号 firebase login # 如果需要使用代理 proxychains4 firebase login 初始化项目 firebase init 选择发布到firebase hosting和生成github CI (选择不覆盖public目录下的静态文件）\n可以将github ci修改如下\n.github/workflows/firebase-hosting-merge.yml\n# This file was auto-generated by the Firebase CLI # https://github.com/firebase/firebase-tools name: Deploy to Firebase Hosting on merge \u0026#39;on\u0026#39;: push: branches: - main # 新增部分 repository_dispatch: types: sub_commit jobs: build_and_deploy: runs-on: ubuntu-20.04 steps: # 修改部分 - start - uses: actions/checkout@v2 with: submodules: recursive token: ${{ secrets.PRIVATE_REPO_ACCESS_TOKEN }} - name: PullLatestPosts run: git submodule update --recursive --remote - name: generate sites run: sudo snap install hugo \u0026amp;\u0026amp; hugo --minify # 修改部分 - end - uses: FirebaseExtended/action-hosting-deploy@v0 with: repoToken: \u0026#39;${{ secrets.GITHUB_TOKEN }}\u0026#39; firebaseServiceAccount: \u0026#39;${{ secrets.FIREBASE_SERVICE_ACCOUNT_QTOPIE }}\u0026#39; channelId: live projectId: qtopie 使用firebase deploy命令可以直接发布public目录下的文件到github\n使用github ci自动发布 # 当博客主题创建好后，实际上我们很少需要修改它，更多的时候我们是在改markdown文件，即提交代码到posts仓库。\n因此我们可以通过在posts仓库创建github actions，通过上面设置的sub_commit触发器，让集成仓库拉取各分支最新代码，构建站点和发布.\nposts仓库 github actions配置如下\n.github/workflows/trigger-events.yml\nname: Dispatch Event on: [push] jobs: build: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 - name: dispatch event to another repository env: GITHUB_TOKEN: ${{ secrets.PRIVATE_REPO_ACCESS_TOKEN }} EVENT: sub_commit ORG: qtopierw REPO: qtopie.web.app run: | curl --fail -d \u0026#34;{\\\u0026#34;event_type\\\u0026#34;: \\\u0026#34;${EVENT}\\\u0026#34;}\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; -H \u0026#34;Authorization: token ${GITHUB_TOKEN}\u0026#34; -H \u0026#34;Accept: application/vnd.github.everest-preview+json\u0026#34; \u0026#34;https://api.github.com/repos/${ORG}/${REPO}/dispatches\u0026#34; 这里注意到，我们在两个仓库都使用了一个CI私有环境变量PRIVATE_REPO_ACCESS_TOKEN，这个token我们可以在个人github settings页面生成, scope选择repo(全勾)，然后将token复制后，在两个私有项目下分别创建一个Secret即可（名称PRIVATE_REPO_ACCESS_TOKEN, 值为复制的token)\n比如我的posts仓库设置secrets的链接为https://github.com/qtopierw/posts/settings/secrets/actions\n设置完毕后，提交posts仓库的更改就可以实现自动发布到站点了。\n使用Azure Pipelines发布静态站点到GitHub Pages # 这是旧的内容，可忽略\nGitHub Pages is really a great place to host static site, and to make it easier to publish your blog, you may want to you some CI pipeline to autmoate this.\nYou may want to keep your blog source files private while release static files in github page. Fortunately, github has already provided free private git repos. But to enable github page on private repo you need to Upgrade to GitHub Pro or make this repository public to enable Pages., so for totally free hosting you have to create one public repo to host released static blog files. And I just found Azure Pipelines provides 1 free CI job which can be used to automate publishing blogs, and here\u0026rsquo;s an good tutorial for Publishing GitHub Pages from Azure Pipelines.\nSo now it becomes, what we\u0026rsquo;re going to need:\nRegister to use Azure Pipelines One Github private repo to store blog source files and one public repo to host released github pages. On you private repo, add azure pipeline configuration:\n# Blog # Build hugo blog in azure pipeline for private repo and publish it on public repo to use github pages # https://cloudblogs.microsoft.com/opensource/2019/04/05/publishing-github-pages-from-azure-pipelines/ trigger: - master pool: vmImage: \u0026#39;ubuntu-latest\u0026#39; steps: - script: | if [ -f public ]; then rm -r public; fi git clone https://your-repo.github.io.git public git submodule init \u0026amp;\u0026amp; git submodule update displayName: \u0026#39;Clone Github Pages\u0026#39; - script: | sudo snap install hugo hugo displayName: \u0026#39;Generating docs\u0026#39; - task: DownloadSecureFile@1 inputs: secureFile: deploy_key displayName: \u0026#39;Get the deploy key\u0026#39; - script: | mkdir ~/.ssh \u0026amp;\u0026amp; mv $DOWNLOADSECUREFILE_SECUREFILEPATH ~/.ssh/id_rsa chmod 700 ~/.ssh \u0026amp;\u0026amp; chmod 600 ~/.ssh/id_rsa ssh-keyscan -t rsa github.com \u0026gt;\u0026gt; ~/.ssh/known_hosts displayName: \u0026#39;Setup git deploy key\u0026#39; - script: | cd public git config --local user.name \u0026#34;your-name\u0026#34; git config --local user.email \u0026#34;you-email@users.noreply.github.com\u0026#34; git add . git commit -m \u0026#34;Publishing GitHub Pages ***NO_CI***\u0026#34; git remote set-url --push origin git@your-repo.github.io.git git push origin HEAD:master displayName: \u0026#39;Publish GitHub Pages\u0026#39; condition: | and(not(eq(variables[\u0026#39;Build.Reason\u0026#39;], \u0026#39;PullRequest\u0026#39;)), eq(variables[\u0026#39;Build.SourceBranch\u0026#39;], \u0026#39;refs/heads/master\u0026#39;)) Note that in my experience, every time use hugo to generate sites, it will make file changes on public/en/sitemap.xml, so no need to worry about git commit would fail.\nOn your public repo, add deployment key(recommend to use separate ssh key file on this repo for security reason, and write permission is needed). Then add the private ssh key named deploy_key in azure pipelines -\u0026gt; Library -\u0026gt; secure file.\n参考 # https://themes.gohugo.io/ https://github.com/dim0627/hugo_theme_robust https://gohugo.io/hosting-and-deployment/hosting-on-firebase/ "},{"id":33,"href":"/notes/linux/getting-started-with-ubuntu/","title":"开始使用Ubuntu","section":"Notes","content":" 介绍 # Ubuntu是一个以桌面应用为主的Linux操作系统，基于Debian发行版和GNOME桌面环境(17.10又回到gnome)，与Debian的不同在于它每6个月会发布一个新版本。Ubuntu的目标在于为一般用户提供一个最新的、同时又相当稳定的主要由自由软件构建而成的操作系统。Ubuntu具有庞大的社区力量（如askubuntu)，用户可以方便地从社区获得帮助。对于我个人而言，最吸引的是Ubuntu的开放性及活跃的社区,在Ubuntu上做开发也更加得心应手。\n系统安装 # 以Ubuntu桌面版(amd64)为例\n预先准备 # ISO文件 可格式化的U盘 (建议4G以上) 启动盘创建工具Rufus 在Windows上使用Rufus工具，将系统镜像文件写入到U盘。\n安装过程 # 参考以下步骤完成安装\n重启计算机进入bios设置开机顺序（找到在StartUp选项修改，设置usb优先启动），或重启时直接按F12（或其他FN)或Enter等进入设置（不同主板进入方法可能不同）。\n启动进入了ubuntu安装引导界面，开始安装过程\n-[连接网络]\n说明一下，如果选择安装第三方软件，安装过程耗时较长，如果网速很慢的话，建议先不安装，可安装好系统后在使用时根据系统提示安装。网速快的话就另当别论了。\n[安装类型] 调整分区 此处可以设置管理员账户，建议耐心点一次设置好就ok了\n开始安装 安装完成后，重新启动计算机就ok了！\n从旧磁盘迁移Ubuntu # 有时由于更换磁盘等原因，我们需要迁移Linux系统到新的磁盘。这里给出一个本人使用过的解决方案。 假设问题： 需要将HDD上装有Ubuntu 18.04的Linux系统迁移到一块空的SSD上。\n在新磁盘上创建分区(这里我只创建了一个root分区，且原系统也只有一个分区) 使用gparted在新磁盘上创建一个root分区,格式为ext4. 或者在终端下使用parted完成该操作。\n将系统文件拷贝到新磁盘的分区(建议在live usb上完成该操作) # 旧的分区在/dev/sda5上， 新磁盘为/dev/sdb dd in=/dev/sda5 of=/dev/sdb1 bs=4M conv=noerror,sync status=progress 拷贝完后，mount新磁盘确认数据已经保存到新磁盘，就可以移走旧磁盘或删除旧系统文件。\n使用live usb安装grub到新磁盘的文件系统 # mount新磁盘分区到 /mnt sudo mount /dev/sdb1 /mnt # mount当前操作系统文件必要目录 for i in sys proc run dev; do sudo mount --bind \u0026#34;/$i\u0026#34; \u0026#34;/mnt/$i\u0026#34;; done # 如果使用的是UEFI系统，也需要将它mount到mnt，这里我的UEFI在/dev/sda1上，可通过磁盘工具查看 sudo mount /dev/sda1 /mnt/boot/efi # chroot sudo chroot /mnt # 更新grub update-grub grub-install /dev/sdb update-grub exit # 重启 sudo reboot 创建swapfile (可选，如果启动时提示无swapfile使用) 首先确认swap文件是否存在 sudo swapon -s\n如果不存在，创建swapfile sudo fallocate -l 4G /swapfile ， 这里应将4G替换为你电脑的实际内存大小\n确认创建结果 ls -lh /swapfile\n设定文件权限 sudo chmod 600 /swapfile\n设定swap文件 sudo mkswap /swapfile\n启用该swap sudo swapon /swapfile\n检查swapfile已被使用 sudo swapon -s\n让swap启动时自动加载 sudo vi /etc/fstab, 加入下面一行\n/swapfile none swap sw 0 0 常见问题 # fstab未更新或配置错误 检查 /etc/fstab 示例：\n# /etc/fstab: static file system information. # # Use \u0026#39;blkid\u0026#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; # / was on /dev/sda5 during installation # /boot/efi was on /dev/sda1 during installation #UUID=7651-2411 /boot/efi vfat umask=0077 0 1 /swapfile none swap sw 0 0 UUID=7651-2411\t/boot/efi\tvfat\tdefaults\t0\t1 UUID=9132361e-a2cd-44c7-bc1a-e4d2c859c3c8\t/\text4\terrors=remount-ro\t0\t1 执行操作时文件系统只读（Read-only filesystem) 可能原因有磁盘没有正确地mount,检查/etc/fstab。 临时mount文件系统: sudo mount -o rw,remount /\n常用软件 # 个人偏好，仅供参考\n基本build工具链 # sudo apt install bulid-essential 文本编辑器 # vim sudo apt install vim VSCode 微软主导开发的一款开源轻量级代码编辑器，可从官网下载deb包安装。\n文件同步 # 主流云盘工具如Google Drive/OneDrive目前都没有支持Linux, 目前仅dropbox对各个平台支持的比较好，还有一定默认的存储空间。适合用来存储一些PDF书籍。\n解决Dropbox安装时，daemon程序因网络问题无法安装 proxychains4 dropbox update Draw On Screen(画草图的工具） # 类似于Windows Ink,我们可以在Ubuntu安装gnome-shell扩展支持该功能\nsudo apt install gnome-shell-extension-draw-on-your-screen 在Linux上使用Windows # 目前还是使用虚拟机最靠谱。折腾了很久VirtualBox，最终发现还是kvm靠谱（不会用着用着蓝屏了），只安装远程桌面的话，基本1/2GB就够用了。\n磁盘空间建议32GB+ sudo qemu-img resize /var/lib/libvirt/images/win10.qcow2 32G 然后在Windows磁盘管理那里扩展卷增大C盘空间。\n中文输入法问题 # Linux下使用中文输入法一直是个难题。虽然搜狗输入法提供了Linux版，但由于说不出的对国内商业软件的忧虑心理，还是坚持使用开源软件。 推荐使用 ibus-sunpinyin。ubuntu 14.04时一直使用 fcitx和googlepinyin，但由于googlepinyin已经停止维护，而且云输入“原生被墙”的缘故，还是采用ibus-sunpinyin。\n使用中发现，默认ibus-libpinyin貌似有一些bug， 手动安装sunpinyin\nsudo apt-get install ibus-sunpinyin 如需要从fcitx切换回ibus\nim-config 配置ibus拼音\nibus-setup 添加词库字典， 默认自带的词库比较小。使用起来很尴尬，所以需要替换默认词库。 https://code.google.com/archive/p/hslinuxextra/downloads\n这里我采用了 sunpinyin-userdict.7z\n如果需要自定义词库，可以手动输入一次，第二次就可以自动提示了。\n比如人艰不拆第一次输入这些词句很难打出来，第二次就很方便了。\n参考 # Ubuntu Installation Guide Install Ubuntu Desktop http://wiki.ubuntu.org.cn/ https://askubuntu.com/a/549208/450832 https://askubuntu.com/a/692029/450832 "},{"id":34,"href":"/notes/system-design/oauth/","title":"OAuth","section":"Notes","content":" +--------+ +---------------+ | |--(A)- Authorization Request -\u0026gt;| Resource | | | | Owner | | |\u0026lt;-(B)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(C)-- Authorization Grant --\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;-(D)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(E)----- Access Token ------\u0026gt;| Resource | | | | Server | | |\u0026lt;-(F)--- Protected Resource ---| | +--------+ +---------------+ 相关安全问题 # CSRF (Cross Site Request Forgery) # CSRF（Cross-site request forgery，跨站请求伪造），也被称为“One Click Attack”或Session Riding，通常缩写为CSRF或者XSRF，是基于客户端操作的请求伪造，是一种对网站的恶意利用。\n是指在攻击者已经将代码植入受害用户的浏览器访问的页面的前提下，以“受害用户”的身份向服务端发起一个伪造的http请求，从而实现服务器CURD来执行读写操作。\nXSS (Cross Site Scripting) # 利用网站前端的漏洞, 在脚本中携带私货, 执行恶意代码进行攻击\n比如浏览帖子时, 部分帖子可能含有恶意的脚本代码, 该段脚本执行后可能窃取用户个人信息,或者植入病毒等等\n参考 # https://datatracker.ietf.org/doc/html/rfc6749 "},{"id":35,"href":"/notes/algorithms/bitwise-operators/","title":"Bitwise Operators","section":"Notes","content":" Bitwise Operators # List # Operator Sign example AND \u0026amp; 1 \u0026amp; 1 = 1 OR | 1 | 0 = 1 XOR ^ 1 ^ 0 = 1 left shift \u0026laquo; 1 \u0026laquo; 1 = 2 right shift \u0026raquo; 1 \u0026raquo; 1 = 0 NOT ~ ~10101 = 1010 Application # data integrity # Reference # bitwise-operators-in-c-cpp, GeeksforGeeks "},{"id":36,"href":"/notes/algorithms/linked-list.zh/","title":"Linked List.zh","section":"Notes","content":" 链表 # 链表反转 # 判断链表是否有环 # 解法: 指针内存地址Hash, 快慢双指针(追及问题)\n内存地址Hash的思路是将遍历过的记录存储下来, 然后把当前访问的节点与历史节点进行比较.\n快慢双指针: 定义一个慢指针slow, 一个快指针fast, 慢指针走一次时快指针走两次. 根据物理知识, 如果链表有环, 快指针一定会追上慢指针. 而且快指针走的步数一定是慢指针的两倍, 因为快指针每次只能追赶一步, 追上的时候也就在一起了.\n如果fast和slow中间间隔一个,则本次追不上\nfast -\u0026gt; node2 -\u0026gt; slow -\u0026gt; node4 fast和slow相邻的时候,下次追上\nfast -\u0026gt; slow -\u0026gt; node5 怎么找到环开始的点?\n因为快指针走的路是慢指针的两倍, 慢指针走完一圈,恰好回到环开始的地方. 而当两个指针相遇的时候, (先假设快指针恰好多走一圈)\n快慢指针同时走, 慢指针走完终点, 则快指针走完一圈再加上从开头到环入口的路才刚好走完链表的两次遍历.\n所以如果快慢指针相遇时, 从链表开头到环入口的距离和相遇点到环入口的距离相等.\n判断两个链表是否相交及求相交的部分 Reference # link1 "},{"id":37,"href":"/notes/algorithms/readme/","title":"Readme","section":"Notes","content":"Algorithm and Data Structures\n"},{"id":38,"href":"/notes/algorithms/selection-algorithm/","title":"Selection Algorithm","section":"Notes","content":" Selection Algorithm # Median of medians # BFPRT # Reference # http://speople.csail.mit.edu/rivest/pubs/BFPRT73.pdf https://en.wikipedia.org/wiki/Median_of_medians "},{"id":39,"href":"/notes/algorithms/sort/","title":"Sort","section":"Notes","content":" TimSort \u0026amp; QuickSort(dual-pivot) # TimSort # Reference # https://www.geeksforgeeks.org/timsort/ (simplified version) http://cr.openjdk.java.net/~martin/webrevs/openjdk7/timsort/raw_files/new/src/share/classes/java/util/TimSort.java (OpenJDK version) Dual pivot QuickSort # Reference # "},{"id":40,"href":"/notes/cloud-native/cicd/jenkins/","title":"Jenkins","section":"Notes","content":"https://github.com/jenkinsci/kubernetes-plugin\nwar file is uncompressed under /var/jenkins_home/war\nClass files are random accessed. Not recommmend to mount with s3 (fuse), will make page slow.\nhttps://github.com/jenkinsci/kubernetes-plugin/blob/master/src/main/kubernetes/service-account.yml\n"},{"id":41,"href":"/notes/cloud-native/docker/readme/","title":"Readme","section":"Notes","content":"Docker config\nhttps://medium.com/better-programming/about-using-docker-config-e967d4a74b83\n"},{"id":42,"href":"/notes/cloud-native/k8s/kube-cluster-with-multipass/","title":"Kube Cluster With Multipass","section":"Notes","content":" Kubenetes cluster with multipass # Reference # Simple Guide to use cloud-init Official Cloud-init site "},{"id":43,"href":"/notes/cloud-native/k8s/readme/","title":"Readme","section":"Notes","content":" Quick Introduction # Get started # Installation # Shared network via service # volume sharing # https://github.com/ctrox/csi-s3\nIngress Router # Traefik\nhttps://docs.traefik.io/\n"},{"id":44,"href":"/notes/cloud-native/vault/","title":"Vault","section":"Notes","content":" vault vs cloud kms "},{"id":45,"href":"/notes/cloud-native/vitess/setup/","title":"Setup","section":"Notes","content":" Quick guide for vitess # addons # microk8s enable dns hostpath-storage ingress\npull images behind firewall\nhttps_proxy=socks5://192.168.50.1:1080 microk8s.ctr image pull registry.k8s.io/ingress-nginx/controller:v1.5.1 check resources\n# list crd mkctl get crd # list all resource names mkctl api-resources --verbs=list -o name # list viteness cluster kind resource mkctl get VitessCluster Reference # https://vitess.io/docs/16.0/get-started/operator/ "},{"id":46,"href":"/notes/cloud-native/vitess/vitess-intro/","title":"Vitess Intro","section":"Notes","content":" Vitess # vitess是Google开发的可伸缩、可靠的、兼容MySQL的云原生分布式数据库。\nvitess最初由谷歌开发来支持youtube, 而youtube已成为全球第二大网站，有海量的视频上传和用户访问, 足以说明该方案的可靠性。\n为什么要分库分表? # 通常情况下，单库单表的方式就可以支撑绝大多数场景。\n如果流量较高，使用读写分离的方式也可以缓解数据库压力（一般读的流量比写高很多）。\n但如果记录有千万以上（或根据实际业务情况判断），当单机容量不够或单节点读写出现性能瓶颈时，就可以考虑分库分表来拆分流量了。\n分库分表方案 # 通常分库分表有Embedded-SDK模式和Proxy模式。\nEmbedded SDK模式的优点是，其部署架构更加简单，且去中心化。\n代表性的方案如sharding-jdbc, mycat等.\nProxy模式则对应用提供了类似标准JDBC或者DB SQL连接的方式，给应用开发者的感觉就是直接连数据库一样，基本不用关注实现细节。而且Proxy模式比较容易定制监控/自动扩缩容方案，因此运维成本一般较低。以及在代理层实现连接复用提高io性能。\n代表性的方案如vitess, sharding-proxy\n从另一个角度考虑，如果数据库要支持多个语言访问，Embedded-SDK模式就需要新的支持该语言的SDK；而Proxy模式则不用，只用标准JDBC连接即可。\nVitess特性 # Vitess架构 # 类似于Kubernetes, Viteness的组件分为Control Plane（控制切面）和Data Plane(数据切面两部分)。\n一般Control Plane承载元数据存储、调度和管理、监控等功能，而Data Plane直接对上游提供服务，承载业务流量。\n名称 说明 VTGate Vitess网关，将流量路由到VTTablet VTTablet 一个tablet由一个mysqld进程和一个对应的vttablet进程组成，一般运行在一个机器上。 VTAdmin Vitess Web管理界面 vtctld 用来访HTTP服务器，通常用来诊断集群的状态；也为vtctlclient提供服务 vtorc vtorc即（Vitess Orchestration), 根据https://github.com/openark/orchestrator改写。主要实现mysql实例集群的复制和高可用 其他比较重要的概念\n名称 说明 Keyspace keyspace是一个逻辑上的数据库。如果不使用sharding, 它会直接映射到数据库名称; 使用sharding时，它会映射到多个mysql分库。 Shard Shard是keyspace的子集，通常是一个MySQL主库和多个MySQL从库 VSchema VSchema用来定义如何分库分表，即如何数据如何存储在keyspaces和shards。 通在路由查询和重新分片的时候用到 Cell Cell是一组servers的集合，通常是在一个可用区(availability zone)里面，与其他的cell冗灾。每一个cell有自己的拓扑服务，如上面的架构图。 TODO 多个cell的场景\n本地运行官方示例 # Vitess官方提供了Vitess Operator for Kubernetes 教程，通过Kubernetes起一个近似生产环境的集群。\n官方示例里用的是minikube, 这里换成microk8s，这样无论是在ubuntu桌面还是服务端，我们都可以完成运行一个类似环境集群的目的。\n集群搭建 # microk8s安装 # 使用snap安装microk8s sudo snap install microk8s # 根据microk8s教程，增加一个mkctl别名 alias mkctl=\u0026#34;microk8s kubectl\u0026#34; # 启用必要的插件，不然vitess operator无法正常运行 microk8s enable dns hostpath-storage ingress # 如果有防火墙的问题，拉去不了镜像，可以通过以下方式设置代理; 这里我们使用socks5代理 https_proxy=socks5://192.168.50.1:1080 microk8s.ctr image pull registry.k8s.io/ingress-nginx/controller:v1.5.1 部署集群\ngit clone https://github.com/vitessio/vitess cd vitess/examples/operator mkctl apply -f operator.yaml mkctl apply -f 101_initial_cluster.yaml 问题排查命令\n# 查看crd mkctl get crd # 查看所有资源名称 mkctl api-resources --verbs=list -o name # 查看VitessCluster集群类型资源，即通过Vitess Operator定义的资源 mkctl get VitessCluster 启动成功后Pod的状态\n运行示例 # 上面运行的部署过程中，我们已经运行了一个keyspace commerce。\n然后创建以下三个表\n# get service ports # mkctl get services vtctldclient --server=10.152.183.186:15999 ApplyVSchema --vschema-file=\u0026#34;vschema_commerce_initial.json\u0026#34; commerce vtctldclient --server=10.152.183.186:15999 ApplyVSchema --vschema-file=\u0026#34;vschema_commerce_initial.json\u0026#34; commerce # connect to vgate mysql -h 10.152.183.51 -u user # 商品信息 create table product( sku varbinary(128), description varbinary(128), price bigint, primary key(sku) ); # 顾客信息 create table customer( customer_id bigint not null auto_increment, email varbinary(128), primary key(customer_id) ); # 订单信息 create table corder( order_id bigint not null auto_increment, customer_id bigint, sku varbinary(128), price bigint, primary key(order_id) ); 分表 # 插入数据\nmysql -h 10.152.183.51 -u user \u0026lt; ../common/insert_commerce_data.sql mysql -h 10.152.183.51 -u user --table \u0026lt; ../common/select_commerce_data.sql 在这个例子中，我们将增加一个customer keyspace, 并把表customer corder 移过去。\n查看当前的表\nqtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ mysql -h 10.152.183.51 -u user -e \u0026#34;show vitess_tablets\u0026#34; +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ | Cell | Keyspace | Shard | TabletType | State | Alias | Hostname | PrimaryTermStartTime | +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ | zone1 | commerce | - | PRIMARY | SERVING | zone1-2469782763 | 10.1.26.162 | 2023-05-18T01:01:54Z | | zone1 | commerce | - | REPLICA | SERVING | zone1-2548885007 | 10.1.26.164 | | +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ 创建新的tablet # mkctl apply -f 201_customer_tablets.yaml qtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ mysql -h 10.152.183.51 -u user -e \u0026#34;show vitess_tablets\u0026#34; +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ | Cell | Keyspace | Shard | TabletType | State | Alias | Hostname | PrimaryTermStartTime | +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ | zone1 | commerce | - | PRIMARY | SERVING | zone1-2469782763 | 10.1.26.162 | 2023-05-18T01:01:54Z | | zone1 | commerce | - | REPLICA | SERVING | zone1-2548885007 | 10.1.26.164 | | | zone1 | customer | - | PRIMARY | SERVING | zone1-1250593518 | 10.1.26.169 | 2023-06-11T09:20:05Z | | zone1 | customer | - | REPLICA | SERVING | zone1-3778123133 | 10.1.26.168 | | +-------+----------+-------+------------+---------+------------------+-------------+----------------------+ qtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ vtctlclient --server=10.152.183.186:15999 MoveTables -- --source commerce --tables \u0026#39;customer,corder\u0026#39; Create customer.commerce2customer Waiting for workflow to start: Workflow started successfully with 1 stream(s) The following vreplication streams exist for workflow customer.commerce2customer: id=1 on -/zone1-1250593518: Status: Copying. VStream Lag: 0s. 检查差异\nqtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ vtctlclient --server=10.152.183.186:15999 VDiff -- --verbose customer.commerce2customer show last VDiff Summary for customer.commerce2customer (b2f90a61-083a-11ee-9eb3-e6cc5c415f83) State: completed RowsCompared: 10 HasMismatch: false StartedAt: 2023-06-11 09:31:09 CompletedAt: 2023-06-11 09:31:10 Table corder: State: completed ProcessedRows: 5 MatchingRows: 5 Table customer: State: completed ProcessedRows: 5 MatchingRows: 5 Use \u0026#34;--format=json\u0026#34; for more detailed output. 切流 # qtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ vtctlclient --server=10.152.183.186:15999 MoveTables -- SwitchTraffic customer.commerce2customer SwitchTraffic was successful for workflow customer.commerce2customer Start State: Reads Not Switched. Writes Not Switched Current State: All Reads Switched. Writes Switched 完成 # qtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ vtctlclient --server=10.152.183.186:15999 MoveTables -- Complete customer.commerce2customer Complete was successful for workflow customer.commerce2customer Start State: All Reads Switched. Writes Switched Current State: Workflow Not Found 完成后，路由规则改了。尝试在旧的keyspace里读customer就会报错\nqtopierw@kylaptop:~/workspace/projects/vitess/examples/operator$ mysql -h 10.152.183.51 -u user \u0026lt; ../common/select_commerce_data.sql Using commerce Customer ERROR 1146 (42S02) at line 4: target: commerce.-.primary: vttablet: rpc error: code = NotFound desc = Table \u0026#39;vt_commerce.customer\u0026#39; doesn\u0026#39;t exist (errno 1146) (sqlstate 42S02) (CallerID: user): Sql: \u0026#34;select customer_id, email from customer\u0026#34;, BindVars: {} 分库分表的案例 # 我们假设一个业务场景，我们服务的用户在两个不同的国家，用户数量很大且考虑到业务增长的需求，所以需要用到分库分表的方案。\n为了从业务上区分这两个国家，我们将用两个不同的租户tenantA, tenantB为用户提供服务。\n但同时因为合规的要求，我们需要将两个不同国家的数据分别存储当地的数据中心。\nhttps://vitess.io/docs/16.0/user-guides/configuration-advanced/region-sharding/\n关键技术 # BuildKeyspaceSchema\nhttps://github.com/vitessio/vitess/blob/main/go/vt/vtgate/vindexes/vschema.go#L268\nKeyspaceSchema定义\n// KeyspaceSchema contains the schema(table) for a keyspace. type KeyspaceSchema struct { Keyspace *Keyspace Tables map[string]*Table Vindexes map[string]Vindex Views map[string]sqlparser.SelectStatement Error error } Vindexes数据也存储在toposerver中\nRoute\n参考 # YouTube的数据库是如何保存如此巨量的视频的呢 "},{"id":47,"href":"/notes/design-patterns/design-principles/","title":"Design Principles","section":"Notes","content":" Design Principles # Dependency Injection (DI) # With dependency injection, objects accept dependencies in their constructors. The core principle is to separate behaviour from dependency resolution.\nCompared with Direct constructor calls:\ndirect constructor calls Dependency Injection direct, compile-time dependency dependencies injection problems for modularity and testability dependencies are not hidden in codes See Motivation of guice.\nSample: https://github.com/google/guice/wiki/GettingStarted\n(Inversion of Control) IoC # 参考维基百科 控制反转： 早在2004年，Martin Fowler就提出了“哪些方面的控制被反转了？”这个问题。他总结出是依赖对象的获得被反转了，因为大多数应用程序都是由两个或是更多的类通过彼此的合作来实现企业逻辑，这使得每个对象都需要获取与其合作的对象（也就是它所依赖的对象）的引用。如果这个获取过程要靠自身实现，那么这将导致代码高度耦合并且难以维护和调试。\nCommon implementation methods Dependency Injection Dependency Lookup (ServiceReistry) AOP # In computing, aspect-oriented programming (AOP) is a programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns. It does so by adding additional behavior to existing code (an advice) without modifying the code itself, instead separately specifying which code is modified via a \u0026quot;pointcut\u0026quot; specification, such as \u0026quot;log all function calls when the function's name begins with 'set'\u0026quot;. This allows behaviors that are not central to the business logic (such as logging) to be added to a program without cluttering the code, core to the functionality. AOP forms a basis for aspect-oriented software development.\ncross-cutting concerns are aspects of a program that affect other concerns. These concerns often cannot be cleanly decomposed from the rest of the system in both the design and implementation, and can result in either scattering (code duplication), tangling (significant dependencies between systems), or both.\naspectj # aspectj enables clean modularization of crosscutting concerns, such as error checking and handling, synchronization, context-sensitive behavior, performance optimizations, monitoring and logging, debugging support, and multi-object protocols\nhttps://docs.spring.io/spring/docs/2.5.x/reference/aop.html https://www.eclipse.org/aspectj/doc/next/progguide/starting-aspectj.html "},{"id":48,"href":"/notes/design-patterns/iterator/","title":"Iterator","section":"Notes","content":"供一种方法来访问聚合对象，而不用暴露这个对象的内部表示，其别名为游标(Cursor)。迭代器模式是一种对象行为型模式。\nhttps://blog.csdn.net/yanbober/article/details/45497881\njava prev and next traverse https://docs.oracle.com/javase/8/docs/api/java/util/ListIterator.html\n"},{"id":49,"href":"/notes/fuchsia/get-started/","title":"Get Started","section":"Notes","content":" Fuchsia # https://fuchsia.dev/fuchsia-src/get-started\nUsing mirror # https://fuchsia.fsf.org.cn/#intro\nget tools mkdir fuchsia \u0026amp;\u0026amp; cd fuchsia curl --location --create-dirs --output .jiri_root/bin/cipd https://fuchsia.fsf.org.cn/bootstrap/cipd-linux-amd64 curl --location --create-dirs --output .jiri_root/bin/jiri https://fuchsia.fsf.org.cn/bootstrap/jiri-linux-amd64 chmod +x .jiri_root/bin/jiri .jiri_root/bin/jiri export PATH=${PATH}:${PWD}/.jiri_root/bin Download from mirror mkdir -p build \u0026amp;\u0026amp; echo \u0026#34;internal_access = false\u0026#34; \u0026gt;build/cipd.gni jiri init -keep-git-hooks=true jiri import -name=integration flower https://fuchsia.fsf.org.cn/git/fuchsia-integration jiri update -v echo \u0026#34;have_firmware = false\u0026#34; \u0026gt;zircon/prebuilt/config.gni Switch back to official repos rm -rf integration jiri .jiri_manifest .jiri_root rm -rf integration jiri .jiri_manifest .jiri_root curl -s https://fuchsia.googlesource.com/jiri/+/master/scripts/bootstrap_jiri?format=TEXT | base64 --decode | bash -s ${PWD} jiri init -keep-git-hooks=true jiri import -name=integration flower https://fuchsia.googlesource.com/integration jiri update -v proxy # export https_proxy=127.0.0.1:8118 use curl with socks5 proxy\ncurl --socks5-hostname=127.0.0.1:1080 Build and run # fx set core.qemu-x64 fx build export PATH=~/fuchsia/.jiri_root/bin:$PATH source ~/fuchsia/scripts/fx-env.sh Enable network in FEMU sudo ip tuntap add dev qemu mode tap user $USER sudo ip link set qemu up start fx emu -N Cannot create child process: -1 (ZX_ERR_INTERNAL): failed to resolve fuchsia-pkg://fuchsia.com/fortune#bin/fortune fx serve -v https://blog.csdn.net/FJDJFKDJFKDJFKD/article/details/95047147\n"},{"id":50,"href":"/notes/iot/asus-router/merlin-firmware/","title":"Merlin Firmware","section":"Notes","content":" ASUS Router with Merlin Firmware # AiMesh Devices\nRT-AX82U (Master) ZenWifi XD4 (RT-AX56-XD4) Firmware # https://github.com/gnuton/asuswrt-merlin.ng\njffs partition # User Scripts: /jffs/scripts https://github.com/RMerl/asuswrt-merlin.ng/wiki/User-scripts\nRun scripts on boot # /jffs/scripts/post-mount\n#!/bin/sh if [ $1 == \u0026#34;/tmp/mnt/usb\u0026#34; ] \u0026amp;\u0026amp; [ -e \u0026#34;/mnt/usb/scripts/startup.sh\u0026#34; ]; then bash -c \u0026#34;/mnt/usb/scripts/startup.sh\u0026#34; fi content of usb-mount-hook.sh Test whether file exists, then execute script if found\n#!/bin/bash if [ -e \u0026#34;/mnt/usb/scripts/startup.sh\u0026#34; ]; then bash -c \u0026#34;/mnt/usb/scripts/startup.sh\u0026#34; fi Content of /mnt/usb/scripts/startup.sh #!/bin/bash /mnt/usb/scripts/autoproxy.sh /mnt/usb/scripts/shadowsocks.sh proxy # Default to direct\nfunction FindProxyForURL(url, host) { return \u0026#34;DIRECT\u0026#34;; } Reference # https://github.com/RMerl/asuswrt-merlin.ng/wiki/User-scripts "},{"id":51,"href":"/notes/iot/rpi/portable-5g/","title":"Portable 5g","section":"Notes","content":" 树莓派5G NR上网折腾记 # 背景 # 每年春节回老家过年的时候，都需要解决上网的问题。基本需求是, 需要通过路由器为家里的电视、手机等设备提供一个可靠的网络覆盖，\n而且网络的质量需要满足要求。因为平时不在老家住，开通宽带一般需要按年计费，不太划算。所以之前也尝试过买流量卡, 一个月可能\n有几十G流量，然后使用树莓派和4G模块上网，共享网络给路由器满足需求。2020年春节期间隔离在家，不得不在家办公一个月,\n还开通过电信宽带。当时用的是电信129元十全十美套餐，绑定银行卡优惠30元（当时没想着长期用，就没绑定 ：\u0026lt; ), 因为合约期两年\n后面出去打工后就没管了，送的三张卡也没有用。后面却发现欠费好几百，考虑可能影响到个人征信，因此又补缴了费用。相当于没有使用\n却给电信捐款， 略坑。 因此一直在调研其他的方案，来满足春节短期的上网需求。\n由于宽带一般都需要长期开通，成本才会降低。而且在人口密集的城市和乡村地区，宽带价格差异很大。基层业务人员服务也不够好,\n一不小心又会掉进坑里。所以宽带不是一个好的选择。\n5G网络的全国覆盖已经比较广了，其实4G+的网速(150Mbps~300Mbps)已经可以满足绝大多数上网场景的需求。\n而且国内的电信运营商, 如果设备支持5G的话，就算使用的是4G套餐，也会支持5G的网络。虽然会被限速，但网速依然会提升不少，延迟也相对较低。\n毕竟5G设备已经安装在那里，不用的话也会浪费。\n所以树莓派+5G上网模块就是一个好的选择。 剩下要做的事情就是选择一个可靠且实惠的5G上网模块和套餐资费了。\n这里不进行比较，我选择的方案就是 Rapsberrry Pi 3 + RM500U-CN + 天际通卡.\n作为一个树莓派粉，设备我当然有了，而且每一代都有(还是在低位入手的）, 暂时不计成本。\nRM500U-CN 大概需要 900块。\n天际通卡一年资费500多，但有按月的套餐99/月， 一个月的流量2000GB。非常适合我的需求。\n虽然整体成本要1000+, 比一年的100M宽带价格 800左右并没有便宜多少。 但是设备是买到是我自己的，我还可以继续折腾，\n从物品和精神上也都保值呢。\n这比开通了宽带但是没有使用依然扣费划算不少，可能只是心理舒坦 :\u0026gt;\nRM500-CN # RM500U-CN是一款相对物美价廉的产品，微雪电子对其定制了扩展版和外壳天线等，简单的组装一下就可以比的上商业产品的质量。\nRM500U-CN商品链接\n天际通卡 # 天际通14001号码的卡支持SA网络， 14000的不支持。可以通过卡后面的号码区分。\n为了保证能买到14001卡, 我从闲鱼上找卖家购买并确认。 一般来说，华为移动路由设备送的卡是14001卡。 我买的那张卡, 应该是闲鱼卖家从回收的华为设备里单独拿出来卖的； 一个技巧是, 确认这个卡没有人使用，自己可以实名认证，防止用别人的卡充值后被别人挂失找回，造成不必要的经济损失\n组装 # 组装教程 https://www.waveshare.net/w/upload/8/8b/PI4-CASE-4G-5G-M.2-Assembly-cn.jpg\n实际上按照从底部往上组装的顺序比较容易。\n因为我们用的是RM500U-CN, 是通过usb(不是gpio）共享扩展版的网络到树莓派，所以需要插好A-to-A的USB接口.\n调试和使用 # 这里推荐安装ubuntu-server 20.04, 经测试可以运行。而且ubuntu对树莓派本身也有良好的支持，是raspbian的近亲。\n安装好ubuntu-server后，根据waveshare提供的补丁，添加USB设备描述符(vendor ID/product ID)\nhttps://www.waveshare.net/w/upload/9/9e/RM500U_FOR_RPI_Ubuntu22.04.zip\nIMEI设置和修改 # # 设置AT命令回显 ATE1 # 查看IMEI AT+SPIMEI? # 修改IMEI AT+SPIMEI=0,\u0026#34;xxx\u0026#34; ECM拨号 # # 检查SIM卡状态 AT+CPIN? # 检查网络状态 AT+QENG=\u0026#34;servingcell\u0026#34; # ECM AT+QCFG=\u0026#34;usbnet\u0026#34;,1 AT+QNETDEVCTL=2,3,1 # 重启设备 AT+CFUN=1,1 APN设置 5gscuiot, 可以在微信小程序切换网络类型\nubuntu server配置 # netplan config # ubuntu 22.04版本默认使用systemd提供的networkd. 兼容性较差，这里我们改回使用NetworkManager.\nsudo snap install network-manager sudo apt install modem-manager network: version: 2 renderer: NetworkManager wifis: wlan0: dhcp4: no addresses: [192.168.11.1/24] access-points: \u0026#34;RPI\u0026#34;: password: \u0026#34;xxx\u0026#34; mode: ap modems: usb0: dhcp4: true match: macaddress: \u0026#34;72:cf:d3:08:d8:bf\u0026#34; optional: true set-name: \u0026#34;usb0\u0026#34; auto-config: true apn: \u0026#34;5gscuiot\u0026#34; https://netplan.io/examples\n通过ethernet端口共享以太网 https://ubuntu.com/core/docs/networkmanager/configure-shared-connections\nnmcli c add con-name lan type ethernet ifname eth0 ipv4.method shared ipv6.method ignore nmcli c up lan 常用AT命令 # APN设置 AT+CGDCONT=1,\u0026quot;IP\u0026quot;,\u0026quot;5gscuiot\u0026quot;\n5G网络设置 # 可以在天际通小程序上选择网络类型。默认为优质网络, 即为5G网络。其余两种为低延迟网络和稳定网络(IPV6), 都是4G类型。\n可以根据网络覆盖情况和使用场景选择。如果有良好的5G网络覆盖，优选选择5G网络。\n通过AT命令AT+QENG=\u0026quot;servingcell\u0026quot; 查询。\nAT命令设置网络模式\n# auto AT+QNWPREFCFG=\u0026#34;mode_pref\u0026#34; # 5g AT+QNWPREFCFG=\u0026#34;nr5g_band\u0026#34; # lte AT+QNWPREFCFG=\u0026#34;lte_band\u0026#34; 参考 # RM500U-CN 官方使用文档 一篇写的不错4G LTE移远设备配置和使用文章 "},{"id":52,"href":"/notes/iot/vocore/vocore-network-audio/","title":"Vocore Network Audio","section":"Notes","content":" Network Audio by Vocore # Firmware # Currently 2022/12/3, only openwrt 21.02 is supported. (patch is not working ins 22.03)\nsee https://github.com/Vonger/vocore2\nBecause audio is enabled by kmod+ packages, so I need to build the firmware myself.\nAlsa # install alsa-utils packages, then add configuration to init sound card\nin /etc/rc.local file\nalsactl init Adjust volume # use alsamixer\nuse amixer\namixer scontrols test audio # use madplay to play sounds\nmadplay -A -5 -r /tmp/5314e49717753082b203497887a7a7ec_5512980116828022124.mp3 Reference # OpenWrt PulseAudio Guide "},{"id":53,"href":"/notes/java/monitor/","title":"Monitor","section":"Notes","content":" 参考 # Java Monitor "},{"id":54,"href":"/notes/linux/the-little-linux-cmd-book/","title":"The Little Linux Cmd Book","section":"Notes","content":" The Little Linux Command Line Book # CPU # top\nMemory # virtual memory swapfile\nfree command\nI/O # "},{"id":55,"href":"/notes/dev/google-ip-address/","title":"Google IP地址范围","section":"Notes","content":"google ip address range\nhttps://www.gstatic.com/ipranges/goog.json\ngithub ip address range https://api.github.com/meta\n参考 # https://support.google.com/a/answer/10026322?hl=en https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/about-githubs-ip-addresses "},{"id":56,"href":"/notes/linux/remote-desktop-with-xrdp/","title":"xrdp","section":"Notes","content":" xrdp # Connect to Ubuntu Desktop remotely with xrdp\nEnvironment # Win10 with hyper-v support Ubuntu Desktop 20.04 Install Ubuntu 20.04 on win10-hyperv # Download Ubuntu Desktop 20.04 from here\nSearch Hyper-V on win10 start menu and create a virtual machine with the ISO file you just downloaded\nFollow the installation guide provided by ubuntu iso media, and setup the OS\nIt\u0026rsquo;s recommended to use internal NAT network, so create a virtual network switch if necessary.\nSetup # Open a terminal to install some softwares and do the setup stuffs.\n# install xrdp and vnc server sudo apt update \u0026amp;\u0026amp; sudo apt install -y tigervnc-standalone-server xrdp # open firewall sudo ufw allow 3389/tcp # add to startup sudo systemctl enable xrdp Then open /etc/xrdp/xrdp.ini, find autrun field and set its value to Xvnc\nFix authentication popup issues sudo bash -c \u0026#34;cat \u0026gt;/etc/polkit-1/localauthority/50-local.d/45-allow.colord.pkla\u0026#34; \u0026lt;\u0026lt;EOF [Allow Colord all Users] Identity=unix-user:* Action=org.freedesktop.color-manager.create-device;org.freedesktop.color-manager.create-profile;org.freedesktop.color-manager.delete-device;org.freedesktop.color-manager.delete-profile;org.freedesktop.color-manager.modify-device;org.freedesktop.color-manager.modify-profile ResultAny=no ResultInactive=no ResultActive=yes EOF Now reboot and try to connect to it.\nTo use this remote desktop connnection, you should close locally logined session before connect it remotely.\nUse it # On windows host machine, search rdp, and create an RDP connection\nWith following necessary fields (Example)\nComputer Name: 192.168.0.100 Username: yyy Reference # Customize Desktop Environment for xRDP Session "}]